\documentclass{homework}
\author{Tomás Pérez}
\class{Condensed Matter Theory - Lecture Notes}
\date{\today}
\title{Theory \& Notes}

\graphicspath{{./media/}}

\begin{document} \maketitle

\subsection{Classical Spin Systems}

Classical spin systems are idealized versions of magnets. Although many magnetic phenomena in materials are inherently quantum mechanical, many properties are well described at least qualitatively by classical spin systems. \\

Each degrees of freedom of a spin system models a magnetic moment at a fixed location. A classical spin is simply the angular momentum vector of a spinning particle, and so can be represented by an arrow, which is assumed to have fixed length. For a spin system to be well-defined, the following requirements are needed 

\begin{itemize}
    \item constraints on where the arrow is allowed to point. For example, in the XY-model, the arrow is constrained to point in a two-diensional plane, and in the Ising model, the arrow is allowed to point in only directions. More complicated examples are the sigma-models, where instead of an arrow, the degrees of freedom take values on some manifold. In this language, the spins in the XY model take values on a circle. \\
    \item Where the spins physically are. For example, they may be at each point of some lattice in some dimension or they could be continuously distributed (ie. an arrow for every point in space eg. a field theory). \\
    \item How the spins themselves interact with one another ie. the energies associated with the possible spin configurations. Two major types of interaction are the ferromagnetic, where the energy is lowered when two spin are aligned, and antiferromagnetic, where the energy is lowered when they point in opposite directions. A given model can include interactions of both types. \\
\end{itemize}

Many many-body physical systems can effectively be treated as being on a lattice. For example, many of these systems are often well treated by utilizing a tight-binding model, where each electron is treated as being located at a fixed nucleus and so live at particular points in space. In some situations, the physics itself arises from the interplay between the degrees of freedom and the particular lattice they live on eg. geometrical frustration in the two-dimensional antiferromagnetic Ising model on a triangular lattice. Calling the two allowed directions in the Ising model as "up" and "down", antiferromagnetic interactions make adjacent spins different. On the square lattice, it is possible to make a low-energy state by alternating up and down spins, but on a triangular lattice this is not the case. Around a triangle, there must be at least two mutually up or down spins adjacent to each other. Such a bond in said to be unsatisfied and so the spins are frustrated, yielding completely new properties different fro the unfrustrated model. \\

\subsubsection{The partition function and correlators}

Consider a general spin chain as a dynamical system. Its spins can take 
any value in a given configuration space, which is a finite-dimensional %or infinite-dimensional 
manifold $\mathcal{M}$. Therefore, assuming that $\mathcal{M}$ is a smooth manifold, the tangent space at $\ket{s}$ is denoted by $T_{\ket{s}} \mathcal{M}$. Then, the cotangent space at $\ket{s}$ is defined as the dual space of $T_{\ket{s}} \mathcal{M}$, 

\begin{equation}
    T_{\ket{s}}^* \mathcal{M} = (T_{\ket{s}} \mathcal{M})^*. \begin{array}{c}
         \textnormal{ Concretely, elements of the cotangent  }  \\
         \textnormal{ space are linear functionals on $T_{\ket{s}} \mathcal{M}$ } \\
         \textnormal{  that is, every element $\bra{s} \in T_{\ket{s}}^* \mathcal{M}$ is a linear map } 
    \end{array} 
\bra{s} : T_{\ket{s}} \mathcal{M} \rightarrow \mathds{C}.
\end{equation}

Then, for for each value $\ket{\mathfrak{s}} \in \mathcal{M}$, the "momentum" $\bra{\mathfrak{s}}$ of the system would take values in the cotangent space $T_s^* \mathcal{M}$ of that space. Thus, the phase space is naturally represented here by the cotangent bundle 

$$
T^* \mathcal{M} = \{(\ket{\mathfrak{s}}, \bra{\mathfrak{s}}) : \ket{\mathfrak{s}} \in \mathcal{M} \textnormal{ and } \bra{\mathfrak{s}} \in T_{\ket{s}}^* \mathcal{M}\}
$$

Thus the basic object classical statistical mechanics is the Boltzmann weight $\prob(n)$. In thermal equilibrium, this is a probability measure that gives the probability that a system will be in a certain configuration $n \in \mathcal{M}$, in terms of said configuration's energy and system's temperature. In other words,

\begin{equation}
    \begin{split}
        \prob : T^* \mathcal{M} \rightarrow \R_{[0,1]} \textnormal{ where }
        \prob{(n)} = \frac{e^{-\beta E_n}}{\mathcal{Z}},
    \end{split}
\end{equation}

where $\mathcal{Z}$ is the partition function, defined by the requirement that the probabilities sum to one, that is 

$$
\mathcal{Z} = \sum_{n \in T^* \mathcal{M}} e^{-\beta E_n}.
$$

Note that if the degrees of freedom take on continuous values, or the model is defined in the continuum, then this sum is replaced by an integral. Note that, indeed, the probability of a given configuration increases as the energy gets lower, and conversely, that as the temperature gets higher and higher, the energies involved must get larger and larger to make a difference. 

\clearpage

\subsection{Quantum Spin Systems}

\clearpage

The Hilbert space of a quantum spin is defined by choosing a representation for the spin operators. A representation of a Lie algebra is a set of three matrices satisfying the commutation relations of the $\mathfrak{su}(2)$-algebra. An \textbf{irreducible representation} is a set of matrices such that no unitary transformation $\mathcal{U} {\bf S}^{a} \mathcal{U}^\dagger$ block-diagonalizes all three matrices. It is known that for the $\mathfrak{su}(2)$-Lie algebra there is exactly one set (up to unitary transformations) of irreducible complex $n\times n$-matrices, for each integer $n$. It is customary to write $n=2s+1$ for all integers and half-integers $s$. A sinsle spin-$s$ quantum particle at a fixed point in space therefore has a Hilbert space $\mathds{C}^{2s+1}$, so the matrices ${\bf S}^a$ are all $(2s+1)\times(2s+1)$. An orthonormal basis is given by the eigenstates of any one of the matrices. 

\begin{itemize}
    \item For $s=0$, the matrices all consist of the number zero, thus this is the trivial representation. 
    \item For $s = \frac{1}{2}$, the chosen basis is ${\bf S}^a = \frac{\hbar}{2} \sigma^a$, this is the fundamental representation.
    \item For $s=1$, the matrices can be written to have entries $({\bf S}^a)_{bc} = i \epsilon_{abc}$, yielding the adjoint representation.
\end{itemize}

In a given representation, an interesting invariant is given by the quadratic Casimir operator, 

$$
{\bf K} = {\bf S} \cdot {\bf S},
$$

which commutes with each of the representation's generators. As a result, it must be proportional to the identity in a given irreducible representation. This is a fundamental consequence of Schur's lemma on theory of representations 

\begin{lemma}Schur's lemma. 
    Let $\mathds{V}$ be a $\mathds{C}$-vector space, associated with a finite-dimensional irreducible representation of an algebra $\mathfrak{A}$ over $\mathds{C}$. Then, let $\phi : \mathds{V} \rightarrow \mathds{V}$ be a homorphism ie. $\phi(av) = a\phi(v), \forall a \in \mathfrak{A}, v \in \mathds{V}$. Then, $\phi = \lambda \mathds{1}_{\mathds{V}}.$ \\
\end{lemma}

\paragraph{\textbf{Spin chain types}}

Some of the most common examples of spin chains are treated as follows, 

\begin{itemize}
    \item The simplest example of a $SU(2)$-symmetric spin Hamiltonian is therefore the nearest-neighbor Heisenberg model, where 

\begin{equation}
    \Hamiltonian_{\mathds{X}\mathds{X}\mathds{X}} = -J \sum_{\langle ij \rangle} {\spin}_i \cdot {\spin}_j = -J \sum_{i=1}^{N} \bigg(\frac{1}{2} (\sigma_i^+ \sigma_{i+1}^{-} + \sigma_i^- \sigma_{i+1}^+) + \frac{1}{4} \sigma_i^z \sigma_{i+1}^z\bigg),
\end{equation}

where in the ferromagnetic case the diagonal terms in the Hamiltonian favour aligned spins, while in the antiferromagnetic case, the diagonal terms favour antialignement. The XXX-Hamiltonian commutes with the magnetization operator by construction. Note that Schur's lemma does not immediately apply since the magnetization operator is reducible. \\

\item The XXZ model is a deformation of the Heisenberg model, breaking the $SU(2)$-model symmetry down to a $U(1)$-subgroup. The XXZ-hamiltonian reads

\begin{equation}
    \Hamiltonian_{\mathds{X}\mathds{X}\mathds{Z}} = - \sum_{\langle jk \rangle} (J_\perp (\spin_j^x \spin_k^x + \spin_j^y \spin_k^y) + J_z \spin_j^z \spin_k^z) = - \sum_{j=1}^{N} \bigg( J_\perp (\sigma_{j}^+ \sigma_{j+1}^- + \sigma_{j}^- \sigma_{j+1}^+) + \frac{\Delta}{2} \sigma_j^z \sigma_{j+1}^z \bigg),
    \label{XXZ hamiltonian}
\end{equation}

which is the most general $U(1)$-symmetric nearest-neighbor interaction for spin-$\frac{1}{2}$ particles. \\

Although this model is no longer $SU(2)$-symmetric, the magnetization operator commutes with the hamiltonian, thus generating a $U(1)$-symmetry. Even though the full $SU(2)$-symmetry is broken, the degrees of freedom are still typically referred to as spins. The sign of $J_z$ alone determines whether the model is ferromagnetic, $J_z > 0$, or antiferromagnetic, $J_z < 0$, since the sign of $J_\perp$ is unimportant in any bipartite lattice, redefining the states by changing the overall sign of the $\spin^x$ and $\spin^y$-operators on half the lattice sites, leaves the algebra unchanged but flips the sign of $J_\perp$. Therefore, the physically meaningful coupling is $\Delta = \frac{J_z}{|J_\perp|}$, so that $\Delta = \pm 1$ for the ferromagnetic and antiferromagnetic spin models, respectively. In the $\Delta \rightarrow \pm \infty$-limit, only the $J_z$ remains, and the model is effectively classical. For the ferromagnetic case $J_z > 0$, all the spins simply line up with the maximum value of ${\bf M}^z$. In the antiferromagnetic case, $\Delta \rightarrow -\infty$ on a bipartite lattice, the spins take their maximum opposite values on every other site. \\

It is easy to check that this Hamiltonian commutes with the magnetization operator, and so preserves a $U(1)\times \mathds{Z}_2$-symmetry. In a classical notion, the $U(1)$-symmetry corresponds to rotations around the $z$-axis, while the $\mathds{Z}_2$ corresponds to flipping all the spins ${\spin_j^a \rightarrow -\spin_j^a}$. \\

\item A still more general Hamiltonian is given by the XYZ-model, which only preserves the spin-flip symmetry. 
\end{itemize}

None of these Hamiltonians correspond to a quantum version of the Ising model. \\

\paragraph{\textbf{Ferromagnets and antiferromagnets}}

Unless geometric frustration is present, in classical systems, there is no significant difference between ferromagnets and antiferromagnets. Eg, with NN-interaction, geometric frustration occurs for lattices that are not bipartite. In a bipartite lattice, the sites can be divided into two sub-lattices such that nearest neighbours always belong to different sub-lattices. A nearest-neighbour antiferromagnetic interaction in a classical model on a bipartite lattice can typically be changed into a ferromagnetic one, by redefining the spin via a flip on all sites on one of the sub-lattices but not on the other (eg. $\uparrow \rightarrow \downarrow$ in the Ising model). The physics of such classical antiferromagnets is therefore essentially equivalent to that of the ferromagnets. \\

Antiferromagnetic quantum systems on non-bipartite lattices also exhibit interesting behaviour. But the interesting thing is that on bipartite lattices, there are a number of important differences between quantum ferromagnets and antiferromagnets. \\

\paragraph{\textbf{Quantum Ferromagnets}}

Consider the Heisenberg interaction $-J \vec{\spin}_1 \cdot \vec{\spin}_2$ across a single bond. For spin-$\frac{1}{2}$ particles, this is a simple $4 \times 4$-matrix acting on the computational basis $\mathcal{B} = \{\ket{\uparrow\uparrow}, \ket{\uparrow \downarrow}, \ket{\downarrow \uparrow}, \ket{\downarrow\downarrow}\}$, yielding 

\begin{equation*} \vec{\spin}_1 \cdot \vec{\spin}_2 = \frac{1}{4} \left(\begin{array}{*{11}c}1 & 0 & 0 & 0 \\0 & -1 & 4 & 0 \\0 & 4 & -1 & 0\\0 & 0 & 0 & 1\\\end{array}\right)\end{equation*}

Diagonalizing this matrix will yield its eigenvalues and its eigenvectors. Given the Clebsh-Gordan decomposition rule $\frac{1}{2} \otimes \frac{1}{2} = 0 \oplus 1$, these eigenvectors can be grouped into the $s=1$-triplet representation and the $s=0$-singlet representation. In effect,

\begin{equation}
    \begin{split}
        \textnormal{triplet}: \ket{\uparrow \uparrow}, \frac{1}{\sqrt{2}} \bigg(\ket{\downarrow \uparrow} + \ket{\uparrow\downarrow}\bigg), \ket{\downarrow\downarrow}, \textnormal{ with } \lambda_i = -\frac{J}{4} \\
        \textnormal{singlet}: \frac{1}{\sqrt{2}} \bigg(\ket{\downarrow \uparrow} - \ket{\uparrow\downarrow}\bigg), \textnormal{ with } \mu_i = +\frac{J}{4}
    \end{split}
\end{equation}

It is simple to check that ${\bf K} = s(s+1)$ in both cases, and that while the singlet is annihilated by all three generators $\vec{\bf S}$, acting with ${\bf S}^+$ and ${\bf S}^-$ takes members of the triplet to each other. One important difference between the ferromagnetic ($J > 0$) and the antiferromagnetic ($J < 0$) models now arises,

\begin{itemize}
    \item if $J>0$, there are multiple ground states for the ferromagnet, each member of the triplet having minimum energy $-J$,
    \item but if $J<0$, the antiferromagnetic ground state, the singlet, is unique. Moreover, the antiferromagnetic ground state is invariant under the $SU(2)$-symmetry, whereas the ferromagnetic ground states are not. \\
\end{itemize}

Additional insight comes from solving the Heisenberg model on a four-site chain, with its Hilbert space being 16-dimensional, by exploiting the model's inner symmetries. The magnetization operator ${\bf M}^z$ commutes with the Hamiltonian, which makes them simultaneously diagonalizable. For perioidic boundary conditions, the translational invariance plays a powerful role. The translation operator is defined by shifting the spins by one site modulo $N$, this is 
\begin{equation}
\begin{split}
    \mathcal{T} : \mathfrak{A}_i \rightarrow \mathfrak{A}_j \\
    \mathcal{T}^{-1} \vec{\bf S}_i \mathcal{T} = \vec{\spin}_{i+1}
\end{split}
\begin{array}{c}
     \textnormal{ where } \mathfrak{A}_i, \mathfrak{A}_j \simeq \mathfrak{su}(2) \blanky \forall i,j. 
\end{array}
\end{equation}

The Hamiltonian commutes with the translation operator when the boundary conditions are periodic, and commutes with the magnetization as well. Thus the Hamiltonian can be broken into blocks acting on states with a fixed eigenvalue of the traslation operator and of the magnetization. \\

Since $\mathcal{T}^N = \mathds{1}$ for an $N$-site chain, the eigenvalues of $\mathcal{T}$ are $\lambda_i = e^{\frac{2\pi i n}{N}}, \forall n \in \mathds{Z}$, from which the corresponding momentum can be defined as $k = \frac{2\pi n}{N}$. Then, the following holds 
$$
    \sum_{n \in \mathds{Z}_{[0, N-1]}} e^{-\frac{2\pi i n}{N}} \mathcal{T}^n \ket{s} = \ket{s} + e^{-\frac{2\pi i}{N}} \ket{s} + \cdots + e^{-\frac{2\pi i (N-1)}{N}}\mathcal{T}^{N-1} \ket{s}.
$$

For example, for a four-site chain, the translational invariance diagonalizes the enire Hamiltonian save for $m=0$ and $k = 0$ or $k = \pi$, since the corresponding eigenstates are 

\begin{equation}
    \begin{split}
        \ket{A} = \frac{1}{\sqrt{2}} \bigg({\uparrow\downarrow\uparrow\downarrow} + e^{-i\pi k} {\downarrow\uparrow\downarrow\uparrow}\bigg), \\
        \ket{B} = \frac{1}{2}  \bigg(\ket{{\uparrow\uparrow\downarrow\downarrow}} + \ket{\downarrow \uparrow \uparrow \downarrow} + \cdots \bigg)
    \end{split} \begin{array}{c}
         \textnormal{with the hamiltonian} \\ \textnormal{ on these} \\ \textnormal{ $k=0$ and $k=\pi$} \\ \textnormal{states being }  
    \end{array}-J \left(\begin{array}{cc}
        -1 & \sqrt{2} \cos\left(\frac{\pi k}{2}\right)  \\
        \sqrt{2} \cos\left(\frac{\pi k}{2}\right) & 0
    \end{array}\right).
\end{equation}

These sector's eigenvalues are therefore $-J$ and $2J$ for $k=0$ and $J = 0$ for $k=\pi$. Again organising the eigenstates into $\mathfrak{su}(2)$-multiplets yield the energy levels divided by $-J$, as follows 

\begin{equation}
    \begin{split}
        & \textnormal{quintuplet}: 1 \\
        & \textnormal{triplets}: \cos(\pi k) (k \neq 0) \\
        & \textnormal{singlets}: -2,0 \textnormal{ for } k=0, \pi \textnormal{ respectively}. 
    \end{split}
\end{equation}

This $\mathfrak{su}(2)$-invariance allows for the construction of the entire multiplet once one of the states is known. \\

As with the two-site chain, the ferromagnetic ground state is a multiplet, whereas the antiferromagnetic is a singlet. For a general $N$-site ferromagnet, the completely ferromagnetic states (all spins up or all spins down) are exact ground states of the Hamiltonian. This suggest using an order parameter for ferromagnetism. 

 . \\

\clearpage

\subsection{XX-model}

Consider the XX-Heisenberg model, with its Hamiltonian given in terms of the traditional $\frac{1}{2}$-spin operators ie. 

\begin{equation}
    {\bf H} = J \sum_{i=1}^{L} ({\bf S}_{j}^{x} {\bf S}_{j+1}^{x} + {\bf S}_{j}^{y} {\bf S}_{j+1}^{y}) - \lambda \sum_{j=1}^{L} {\bf S}_{j}^{z},
    \label{XX hamiltonian}
\end{equation}

which describes interacting spins in a one-dimensional chain, with periodic boundary conditions. \eqref{XX hamiltonian}'s first terms represents nearest neighbour interactions in the $x$ and $y-$directions  interactions, with $J$ being either positive or negative and quantifying the strength and type of interactions, while the second term represents a magnetic field of strength $\lambda$, applied in the $z$-direction of the spins. \\

\paragraph{\textbf{Exact solution}}

In order to solve this problem, it is necessary to rewrite \eqref{XX hamiltonian} and apply a Jordan-Wigner transformation, mapping the spin problem into a fermionic problem. But first, it is convenient to write the spin-operators in terms of the raising and lowering $\mathfrak{su}(2)$-operators, ie.

$$
    \spin_j^{\pm} = \spin_j^{x} \pm i \spin_j^{y} \blanky \Rightarrow \blanky \begin{array}{c}
         \spin_{j}^x = \frac{1}{2} (\spin_j^+ + \spin_j^-), \\
          \\
         \spin_{j}^y = \frac{1}{2i} (\spin_j^+ - \spin_j^-). 
    \end{array}
$$

Then, the XX-Hamiltonian can be re-written as 

\begin{equation}
     {\bf H} = \frac{J}{2} \sum_{i=1}^{L} ({\bf S}_{j}^{+} {\bf S}_{j+1}^{-} + {\bf S}_{j}^{-} {\bf S}_{j+1}^{+}) - \lambda \sum_{j=1}^{L} {\bf S}_{j}^{z}
     \label{raising Hamiltonian}
\end{equation}

where the interacting terms in the first summation, flip neighboring spins if said spins are anti-aligned\footnote{In effect, consider for example, a two-spin problem. Then, the interaction term is given by 

$$
\spin_1^+ \spin_2^- + \spin_1^- \spin_2^+,
$$

and consider an anti-aligned state $\ket{\downarrow\uparrow}$. Then, the action of the previous two-spin operator over this state yields

$$
(\spin_1^+ \spin_2^- + \spin_1^- \spin_2^+) \ket{\downarrow\uparrow} = \ket{\uparrow\downarrow} + 0,
$$

since $\spin_1^- \spin_2^+$ destroys the state. Similarly, $(\spin_1^+ \spin_2^- + \spin_1^- \spin_2^+)\ket{\uparrow\downarrow} = \ket{\downarrow\uparrow}$. However, note that, should both spins be either up or down, the state remain invariant under the action of the two-spin operator. 

\begin{align}
    (\spin_1^+ \spin_2^- + \spin_1^- \spin_2^+) \ket{\downarrow\downarrow} = \ket{\downarrow\downarrow} \textnormal{ and } (\spin_1^+ \spin_2^- + \spin_1^- \spin_2^+) \ket{\uparrow\uparrow} = \ket{\uparrow\uparrow} 
\end{align}}. In addition, the XX-Hamiltonian has a total magnetization symmetry, since the Hamiltonian given by \eqref{raising Hamiltonian} conmutes with the magnetization operator. \\

Now, we use a Jordan-Wigner transformation whereby the spin operators are mapped to fermionic operators, as follows 

\begin{equation}
    \begin{array}{c}
         \spin_j^z = f_j^\dagger f_j - \frac{1}{2}  \\
         \\
         \spin_j^- = \exp\bigg(i\pi \sum_{\ell = 1}^{L-1} f_\ell^\dagger f_\ell \bigg) \\
         \\
         \spin_j^+ = \exp\bigg(-i\pi \sum_{\ell = 1}^{L-1} f_\ell^\dagger f_\ell \bigg) 
    \end{array}
    \label{JW tr}
\end{equation}

Under the Jordan-Wigner map, nearest-neighbours spin flipping is translated into to nearest-neighbours fermionic hopping, ie. $\spin_{j}^{+} \spin_{j+1}^{-} = f_{j}^{\dagger} f_{j+1}$ and $\spin_{j}^{-} \spin_{j+1}^{+} = f_{j+1}^{\dagger} f_{j}$. However, due to the boundary conditions' periodicity, the XX-Hamiltonian cannot be rewritten as a fermionic model yet since (it will contain an additional boundary term), for example, the fermionic counterparts to the $\spin_{L}^{+} \spin_{1}^{-}$ interaction are highly non-local operators and are not desirable. Indeed, under the Jordan-Wigner mapping 

\begin{equation*}
    \spin_{L}^{+} \spin_{1}^{-} = f_L^\dagger \exp\bigg(-i\pi \sum_{\ell = 1}^{L-1} f_\ell^\dagger f_\ell \bigg) f_1,
\end{equation*}

which is not problematic, since it accounts for all $L$-lattice sites. Let

\begin{equation}
    \begin{array}{c}
       \spin_{L}^{+} \spin_{1}^{-} = \mathcal{Q} f_L^\dagger f_1 \textnormal{  and  }
       \spin_{L}^{-} \spin_{1}^{+} = \mathcal{Q} f_1^\dagger f_L,
    \end{array}
\end{equation}

then \eqref{raising Hamiltonian} can be rewritten as 

\begin{equation}
    {\bf H} = \frac{J}{2} \sum_{i=1}^{L-1} \bigg(f_{j}^{\dagger} f_{j+1} + f_{j+1}^{\dagger} f_j\bigg) - \lambda \sum_{j=1}^{L} \bigg(f_{j}^{\dagger} f_{j} - \frac{1}{2}\bigg) + \frac{J}{2} \mathcal{Q} (f_L^\dagger f_1 + f_1^\dagger f_L),
    \label{fermionic no boundary}
\end{equation}

where the first term accounts for fermionic nearest-neighbour hopping, the second term accounts for the magnetic field, and the third term being the non-local boundary term. Note that this fermionic Hamiltonian hasn't got any type of boundary conditions, since the $L$-lattice site is disconnected in any way whatsoever from the first lattice site. Then, the standard procedure is to add and subtract terms from the Hamiltonian, so that the nearest-neighbour hopping term in \eqref{fermionic no boundary} can also have periodic boundary conditions, thus yielding 

\begin{equation}
    {\bf H} = \frac{J}{2} \sum_{i=1}^{L} \bigg(f_{j}^{\dagger} f_{j+1} + f_{j+1}^{\dagger} f_j\bigg) - \lambda \sum_{j=1}^{L} \bigg(f_{j}^{\dagger} f_{j} - \frac{1}{2}\bigg) + \frac{J}{2} (\mathcal{Q}-1) (f_L^\dagger f_1 + f_1^\dagger f_L),
    \label{true fermionic hamiltonian}
\end{equation}

where now the fermionic hopping term has the standard boundary conditions. The third term, since it does not involve any type of summation over lattice sites, only contributes at $\mathcal{O}\bigg(\frac{1}{L}\bigg)$-order to any microscopic quantity. In the thermodynamic limit, this non-local term can be dropped, thus yielding an $\mathcal{O}(L)$-Hamiltonian given by 
\begin{equation}
    {\bf H} = \frac{J}{2} \sum_{i=1}^{L} \bigg(f_{j}^{\dagger} f_{j+1} + f_{j+1}^{\dagger} f_j - \lambda f_{j}^{\dagger} f_{j}\bigg) + \frac{\lambda L}{2},
    \label{L-order fermionic hamiltonian}
\end{equation}

which is now fully cyclic and where its operators obey fermionic algebras. This Hamiltonian can then be diagonalized via a discrete Fourier transform on the fermionic operators 

\begin{align}
    f_j &= \frac{1}{\sqrt{L}} \sum_{\substack{k = {2\pi m/L}\\
    m \in \mathds{Z}_{[1, L]} }}
                  e^{ijk} d_k, & f_j^{\dagger} &=\frac{1}{\sqrt{L}}  \sum_{\substack{k = {2\pi m/L}\\
    m \in \mathds{Z}_{[1, L]}}} e^{-ijk} d_k^{\dagger},
\end{align}

with the inverse transformation given by 

\begin{align}
    d_k &= \frac{1}{\sqrt{L}} \sum_{j=1}^{L}
                  e^{-ikj} f_j &  d_k^{\dagger} &= \frac{1}{\sqrt{L}} \sum_{j=1}^{L}
                  e^{ikj} f_j^{\dagger}.
\end{align}

Note that the $d_k$-operators follow the standard fermionic anticonmutation algebra. Note as well, that the $f_j$-vacuum state, defined such that $f_j \ket{0}_f = 0, \blanky \forall j$, is the same as the $d_k$-vacuum state, defined such that $d_j \ket{0}_d = 0, \blanky \forall k$, ie. $\ket{0}_f = \ket{0}_d$. Another important relationship is the Fourier transform's consistency condition, ie. 

$$
\sum_{j=1}^{L} e^{i(k-q)j} = L \delta_{kq}.
$$

Under the Fourier transform, \eqref{L-order fermionic hamiltonian}'s terms are mapped as follows 

\begin{align*} 
    \sum_{j=1}^{L} f_j^\dagger f_{j+1} &= \sum_{j=1}^{L} \frac{1}{L} \sum_{k, \blanky q} e^{-ikj} e^{iq(j+1)} d_k^\dagger d_q = \sum_{j=1}^{L} \frac{1}{L} \sum_{k, \blanky q} e^{i(q-k)j} e^{iq} d_k^\dagger d_q \\
    &= \sum_{k, \blanky q} \frac{1}{L} e^{iq} \delta_{qk} d_k^\dagger d_q = \sum_{k} e^{ik} d_k^\dagger d_k \\
    \sum_{j=1}^{L} f_{j+1}^\dagger f_{j} &=  \sum_{j=1}^{L} \frac{1}{L} \sum_{k, \blanky q} e^{-ik(j+1)} e^{iqj} d_k^\dagger d_q = \sum_{j=1}^{L} \frac{1}{L} \sum_{k, \blanky q} e^{i(q-k)j} e^{-ik} d_k^\dagger d_q \\
    &= \sum_{k, \blanky q} \frac{1}{L} e^{-ik} \delta_{qk} d_k^\dagger d_q = \sum_{k} e^{-ik} d_k^\dagger d_k \\
    \sum_{j=1}^{L} f_{j}^\dagger f_{j} &=  \sum_{j=1}^{L} \frac{1}{L} \sum_{k, \blanky q} e^{-ikj} e^{iqj} d_k^\dagger d_q = \sum_{j=1}^{L} \frac{1}{L} \sum_{k, \blanky q} e^{i(q-k)j}  d_k^\dagger d_q \\
    &= \sum_{k, \blanky q} \frac{1}{L} \delta_{qk} d_k^\dagger d_q = \sum_{k} d_k^\dagger d_k \\
\end{align*} 

Therefore, using these identities, the new Hamiltonian is given by 

\begin{equation}
\begin{split}
    {\bf H} &= \frac{J}{2} \sum_{k} \bigg(e^{ik} d_{k}^{\dagger} d_{k} + e^{-ik} d_{k}^{\dagger} d_k - \lambda d_{k}^{\dagger} d_{k}\bigg) + \frac{\lambda L}{2} \\
    &= \sum_{k} \bigg(J \cos k - \lambda \bigg)d_{k}^{\dagger} d_{k} + \frac{\lambda L}{2},
\end{split}
\end{equation}

which can be rewritten as 

\begin{align}
    \alignedbox{{\bf H} }{= \sum_{k} \epsilon_k d_k^\dagger d_{k} + \frac{\lambda L}{2} \begin{array}{c}
         \textnormal{ with the eigenvalues being given by } \epsilon_k = J \cos k - \lambda + \frac{\lambda L}{2} \\
         \textnormal{ and the eigenvectors being given by } \ket{E_n} = \prod_{n}  (d_k^\dagger)^n, \\
         \textnormal{                    with eigenvalue $E_n = \sum_{n} \epsilon_n $}  
    \end{array}}
\end{align}

where, $k = \frac{2\pi m}{L}, \blanky m = -\frac{L}{2} + 1, \cdots \frac{L}{2}, $ ie. $k \in (-\pi, \pi]$, this is called the first Brillouin zone. Thus the problem has been solved \\

As for its thermal properties, since this is a fermionic model, the fermions will obey the Fermi-Dirac distribution, ie. 

\begin{equation}
    \mathcal{N}_{jk} = \langle d_j^\dagger d_k \rangle_{\textnormal{th}} =  \frac{1}{1+e^{\beta \epsilon_k + \mu}} \delta_{jk} 
\end{equation}

\clearpage

\subsubsection{Quantum Phase Transition}

The system's groundstate is defined such that 

\begin{equation}
    \bra{E_G} d_k^\dagger d_k \ket{E_G} = 1 \textnormal{ if } \epsilon_k \leq 0 \textnormal{ and } \bra{E_G} d_k^\dagger d_k \ket{E_G} = 0 \textnormal{ if } \epsilon_k > 0.
\end{equation}

Then the groundstate energy is given by 

\begin{equation}
    E_G = \sum_{k} \epsilon_k \bra{E_G} d_k^\dagger d_k \ket{E_G}.
\end{equation}

Now, there exists a momenta $k_F$ such that $\epsilon_{k_F} = 0$, with $k_F$ being the Fermi momentum, ie. $\epsilon_{k_f} = J \cos k_f - \lambda$. The previous equation depends both on the coupling strength $J$ and the magnetic field strength $\lambda$. From the previous equation some special cases arise, namely 

\begin{itemize}
    \item when $\lambda < -J$, which yields a Fermi momentum $k_F = \pi$,
    \item when $|\lambda| \leq J$, which yields a Fermi momentum $k_F = \arccos \bigg(\frac{\lambda}{J}\bigg)$,
    \item when $\lambda > J$ which yields $k_F = 0$.
\end{itemize}

Therefore, the system groundstate will be defined by the following relations, 

\begin{equation}
    \begin{array}{c}
         \bra{E_G} d_k^\dagger d_k \ket{E_G} = 1  \\
         \\
         \textnormal{ if } k \in [-\pi, -k_F] \cup [k_F, \pi],
    \end{array} \textnormal{ and }  \begin{array}{c}
         \bra{E_G} d_k^\dagger d_k \ket{E_G} = 0  \\
         \\
         \textnormal{ if } k \in [-k_F, k_F].
    \end{array}
\end{equation}

\blanky \\

The total magnetization operator is defined as the sum of the $\spin_z$ operators, along the entire chain ie. ${\bf M}^z = \sum_{j=1} \spin^z_j$. Under the Jordan-Wigner transformation, $\spin^z_j = f_j^\dagger f_j - \frac{1}{2}$. In turn, these fermionic number operators can be mapped to fermionic number operators acting on momentum space, ie. $\sum_{j=1}^{L} f_j^\dagger f_j = \sum_k d_k^\dagger d_k$. This entails

\begin{equation}
    {\bf M}^z = \sum_{k} \bigg(d_k^\dagger d_k - \frac{1}{2}\bigg).
\end{equation}

Then the total magnetization operator's expectation value for the groundstate can be calculated. Given the system's fermionic nature, momentum eigenmodes are either occupied or unoccupied, contributing only one or zeros respectively. Then, this expectation value yields

\begin{equation}
    \bra{E_G} {{\bf M}^z} \ket{E_G} = \sum_{k=-\pi}^{-k_F} 1 + \sum_{k=k_F}^{\pi} 1 - \frac{1}{2} \sum_{k=-\pi}^{\pi} 1 \\
    = \frac{1}{2} \bigg( \sum_{k=-\pi}^{-k_F} 1 + \sum_{k=k_F}^{\pi} 1 - \sum_{k = -k_F}^{k_F} 1  \bigg), \label{total magnetization ev}
\end{equation}

where the total magnetization expectation value is just half the difference of two competing summations, related to the negative and positive eigenmodes. Defining the total magnetization per site operator, ${{\bf m}}^z = \frac{1}{L} {\bf M}^z$. Now, as the chain gets progressively bigger, with more and more lattice sites, the summations in \eqref{total magnetization ev} can be approximated by Riemannian integrals, ie.

\begin{equation*}
    \sum_{k} f(k) = \frac{1}{\Delta k} \sum_{k} f(k) \Delta k \overset{L \rightarrow \infty}{\rightarrow} \frac{L}{2\pi}\int_{k \in \mathds{B}\mathds{Z}} dk f(k) \textnormal{ where } \Delta k = \frac{2\pi}{L}.
\end{equation*}

Using this trick, \eqref{total magnetization ev} can be rewritten as 

\begin{align}
    \langle {{\bf m}}^{z} \rangle_{G} &= \frac{1}{4\pi} \bigg(\int_{-\pi}^{-k_F} dk + \int_{k_F}^{\pi} dk - \int_{-k_F}^{k_F} dk \bigg) = \frac{1}{4\pi} \bigg(-k_F + \pi + \pi - k_F - k_F + k_F\bigg) \\
    &= \frac{1}{2} - \frac{k_F}{\pi},
\end{align}

which yields the total magnetization per lattice site. Note that at $\lambda < J$, $k_F = \pi$ whereby there is total polarization ie. $\langle {{\bf m}}^{z} \rangle_{G} = -\frac{1}{2}$. Similarly, for $\lambda > J$, $k_F = 0$ and then $\langle {{\bf m}}^{z} \rangle_{G} = \frac{1}{2}$. However, if $|\lambda| \leq J$, then $k_F = \arccos\bigg(\frac{\lambda}{J}\bigg)$, which then yields a total magnetization per lattice site given by 
\begin{equation} \langle {{\bf m}}^{z} \rangle_{G}  = \left\{
    \begin{array}{cc}
          \frac{1}{2} - \frac{1}{\pi}\arccos\bigg(\frac{\lambda}{J}\bigg)&  \textnormal{ if } |\lambda| \leq J  \\
          \\
          -\frac{1}{2} & \textnormal{ if } \lambda < J  \\
          \\
          \frac{1}{2} & \textnormal{ if } \lambda > J  \\
    \end{array} \right.
\end{equation}

Another interesting quantity is the total magnetic susceptibility, which can be written in terms of the total magnetization per lattice site as follows 

\begin{align}
    \chi = \bigg(\frac{\partial \langle {{\bf m}}^{z} \rangle_{G}}{\partial \lambda}\bigg) \Rightarrow \chi = \left\{ \begin{array}{cc} 
         \frac{1}{J \pi \sqrt{1- \frac{\lambda^2}{J^2}}} \textnormal{ if } |\lambda| \leq J  \\
         \\
          0 \textnormal{ if } \lambda < J \\ 
         \\
          0 \textnormal{ if } \lambda > J  \\
              \end{array} \right., \label{}
\end{align}

which is divergent if $\lambda = J$. This shows that the XX-Heisenberg model has a second order (since there is no latent heat involved it can't be a first order phase transition) quantum phase transition, with an associated power law with a critical exponent.  \\

%\subsection{XXZ-model}

\clearpage

\subsection{Bethe ansatz}

\paragraph{\textbf{Heisenberg XXX-chain}}

Consider a one-dimensional lattice with $N$ lattice sites and a $\frac{1}{2}$-spin particle positioned at every lattice site, which have a nearest neighbour spin-spin interaction. Each particles either has spin up or spin down, generating a two-dimensional local Hilbert space $\vds_n$. Strictly speaking there are two possible topologies for a one-dimensional chain, open or closed. Consider the XXX-Hamiltonian with closed topology, given by 

\begin{equation}
\begin{split}
    {\bf H} &= J \sum_{n=1}^{N} \bigg(\vec{\spin}_n \cdot \vec{\spin}_{n+1} - \frac{1}{4} \mathds{1}^{\otimes N} \bigg) \\
    &= \frac{J}{4}\sum_{n=1}^{N} \bigg(\vec{\sigma}_n \cdot \vec{\sigma}_{n+1} - \frac{1}{4} \mathds{1}^{\otimes N} \bigg).
    \label{XXX model}
\end{split}
\end{equation}

Note that $J < 0$ models a ferromagnetic state while $J > 0$ models an anti-ferromagnetic state. A ferromagnetic state refers to a state where all the spins are alligned while an anti-ferromagnetic state refers to a state where adjacent spins are anti-aligned within the domain. 


The main point of the Bethe solution is that XXX Heisenberg Hamiltonian, which defines the model, can be expressed in terms of a complex-valued $\bm{\mathcal R}$-matrix which is a solution of the Yang-Baxter equation, thus leading to the model's integrability. The most convenient approach is to construct a transfer $\bm{\mathcal{T}}$-matrix -a one parameter commutative family of operators acting on the full state space of the Heisenberg spin chain. \\

\paragraph{\textbf{Some fundamentals of Matrix Theory}}

Let $\mathds{V}$ be an $n$-dimensional $\mathds{C}$-vector space and let $k \in \mathds{1}_n \textnormal{ such that } \in \mathds{N}_{[0, k]}$. Let $\mathfrak{J} = \mathds{1}_n / \mathds{1}_k = \{k+1,\cdots, n\}$. Let $A \in \textnormal{GL}(n, \mathds{C})$, which can be written in block notation as 
\begin{equation}
    A = \left(\begin{array}{cc}
        A_{\mathcal{I}} & A_{\mathcal{I} \mathfrak{J}}  \\
        A_{\mathfrak{J} \mathcal{I}} & A_{\mathfrak{J}}
    \end{array}\right) \begin{array}{c}
         \mathds{C}^k  \\
         \mathds{C}^{n-k}
    \end{array} \textnormal{ where } \begin{array}{cc}
        A_{\mathcal{I}} \in \textnormal{GL}(k, \mathds{C}),  &  A_{\mathcal{I} \mathfrak{J}} \in \textnormal{GL}(k \rightarrow n-k, \mathds{C}), \\
        A_{\mathfrak{J} \mathcal{I}} \in  \textnormal{GL}(n-k \rightarrow k, \mathds{C}), & A_{\mathfrak{J}}  \in \textnormal{GL}(n-k, \mathds{C}),
    \end{array} 
\end{equation}

This notation is consistent with the common matrix operations. The same idea holds for writing down a  block matrix representation for a linear operator with respect to a given subspace. Let $\mathcal{S} \subset \mathds{C}^n$ be a $k$-dimensional vector subspace, such that $\mathds{C}^n = \mathcal{S} \oplus \mathcal{S}^{\perp}$. Then, every linear operator in $\textnormal{End}(\mathds{C}^n)$ can be rewritten as a $\twobytwo$-block-matrix, with its entries being matrices of a given dimension ie. \footnote{
For example, consider the orthogonal projector over $\mathcal{S}$, labelled $P_{\mathcal{S}}$. In this notation, its matrix representation is given by 

\begin{equation*}
    P_{\mathcal{S}} = \left( \begin{array}{cc}
       \mathcal{I} & 0 \\
       0 & 0
    \end{array} \right) \begin{array}{c}
         \mathcal{S} \\
         \mathcal{S}^\perp
    \end{array} 
\end{equation*}}

\begin{equation*}
\begin{split}
    A \in \textnormal{End}(\mathds{C}^n) &\rightarrow \exists! \left\{\begin{array}{cc}
        A_{\mathcal{S}} \in \textnormal{GL}(k, \mathds{C}),  &  A_{\mathcal{S}, \mathcal{S}^\perp} \in \textnormal{GL}(k \rightarrow n-k, \mathds{C}), \\
        A_{\mathcal{S}^\perp, \mathcal{S}}  \in  \textnormal{GL}(n-k \rightarrow k, \mathds{C}), & A_{\mathcal{S}^\perp} \in \textnormal{GL}(n-k, \mathds{C}),
    \end{array} \right\} / \\
   &A = \left( \begin{array}{cc}
       A_{\mathcal{S}} & A_{\mathcal{S}, \mathcal{S}^\perp}  \\
       A_{\mathcal{S}^\perp, \mathcal{S}} & A_{\mathcal{S}^\perp} 
    \end{array} \right) \begin{array}{c}
         \mathcal{S} \\
         \mathcal{S}^\perp
    \end{array}
    \end{split}
\end{equation*}

\textnormal{ } \\

\paragraph{\textbf{The Lax operator}} Consider an XXX spin chain with $N$ sites and a corresponding Hilbert space given by 

\begin{align}
    \mathds{H} \simeq \bigotimes_{n=1}^{N} {\mathds{V}_n} \textnormal{ where } {\mathds{V}_n} \simeq \ctwo \begin{array}{c}
         \textnormal{To these individual Hilbert spaces, additional}  \\
         \textnormal{auxiliary, non-physical, spaces $\mathds{V}_a \simeq \ctwo$, can be added. } \\
    \end{array}
\end{align}

The algebraic Bethe ansatz' basic tool is the lax operator $\bm{\mathcal{L}}$, whose definition is as follows. 

\begin{df}
   The lax operator $\bm{\mathcal{L}}$ can be defined as an operator which involves the local quantum space $\mathds{V}_n$ and the auxiliary space $\mathds{V}_a$, as follows 

\begin{equation}
    \begin{array}{c}
         \bm{\mathcal{L}} : \mathds{V}_n \otimes \mathds{V}_a \rightarrow \mathds{V}_n \otimes \mathds{V}_a \\
         \\
         \bm{\mathcal{L}}_{n, a} = u(\mathds{1}_n \otimes \mathds{1}_a) + i \sum_{\alpha} \spin_n^\alpha \otimes \sigma_{a}^\alpha, \blanky \forall n \leq N \\
         %= u^{\mu} {S}_{\nu} \sigma^{\nu} \textnormal{ where $u^{\mu} = (u, i,i,i)$}
    \end{array} \begin{array}{c}
         \textnormal{ where $\mathds{1}_n$ and $\spin_n^\alpha$ act on $\mathds{V}_n $} \\
         \\
         \textnormal{ while $\mathds{1}_a$ and $\spin_a^\alpha$ act upon $\mathds{V}_a$ and where the}\\
         \\
         \textnormal{ complex-valued $u$-parameter is the spectral parameter.}
    \end{array}
    \label{lax operator}
\end{equation}
\end{df}

 Note that \cref{lax operator} can be rewritten as 

\begin{equation}
    \begin{split}
    \bm{\mathcal{L}}_{n, a} &= u(\mathds{1}_n \otimes \mathds{1}_a) + i \sum_{\alpha} \spin_n^\alpha \otimes \sigma_{a}^\alpha \\
    %&= u \left(\begin{array}{cc}
    %    \mathds{1}_n & 0  \\
    %    0 & \mathds{1}_a 
    %\end{array}\right) + i \spin^{x}_{n} \otimes \left(\begin{array}{cc}
    %    0 & 1 \\
    %    1 & 0
    %\end{array}\right)_a + i \spin^{y}_{n} \otimes \left(\begin{array}{cc}
    %    0 & -i \\
    %    i & 0 
    %\end{array}\right)_a + i \spin^{z}_{n} \otimes \left(\begin{array}{cc}
    %    1 & 0  \\
    %    0 & -1
    %\end{array}\right)_a \\
    &= \left(\begin{array}{cc}
       u \mathds{1}_n + i \spin^{z}_{n} & i \spin^{x}_{n} + \spin^{y}_{n} \\
       i \spin^{x}_{n} - \spin^{y}_{n}  & u \mathds{1}_n - i \spin^{z}_{n}
    \end{array}\right)_a = \left(\begin{array}{cc}
       u \mathds{1}_n + i \spin^{z}_{n} & i \spin^{-}_{n} \\
       i \spin^{+}_{n} & u \mathds{1}_n - i \spin^{z}_{n}
    \end{array}\right)_a,
    \end{split}
\end{equation}
    
which is a $2 \times 2$-matrix in the auxiliary space $\mathds{V}_a$ and the matrix entries are operators acting on the physical Hilbert space $\mathds{V}_n$. \\

Consider now the following mathematical object. 

\begin{df}
    Let the permutation operator be
    
    \begin{equation}
        \bm{\mathcal P}_{n,a} = \frac{1}{2} \bigg(\mathds{1}_n \otimes \mathds{1}_a + \sum_{\alpha}\sigma_n^{\alpha}  \otimes \sigma_n^{\alpha} \bigg) = \frac{1}{2} \sigma^{n \mu}\sigma^{\alpha}_{\mu}
        \label{permutation op}
    \end{equation}
    
    which \footnote{Note that the permutation operator can be written as a $2 \times 2$-matrix in the auxiliary space $\mathds{V}_a$,
\begin{equation} 
\begin{split}
    \bm{\mathcal P}_{n,a} &= \frac{1}{2} \left[ \left(\begin{array}{cc}
        \mathds{1}_n & 0  \\
        0 & \mathds{1}_a 
    \end{array}\right) + \sigma^{x}_{n} \otimes \left(\begin{array}{cc}
        0 & 1 \\
        1 & 0
    \end{array}\right)_a + \sigma^{y}_{n} \otimes \left(\begin{array}{cc}
        0 & -i \\
        i & 0 
    \end{array}\right)_a + \sigma^{z}_{n} \otimes \left(\begin{array}{cc}
        1 & 0  \\
        0 & -1
    \end{array}\right)_a \right] \\
    &= \left(\begin{array}{cc}
       \mathds{1}_n + \sigma^{z}_{n} &  \sigma^{x}_{n} - i\sigma^{y}_{n} \\
       \sigma^{x}_{n} + i\sigma^{y}_{n}  & \mathds{1}_n - \sigma^{z}_{n}
    \end{array}\right)_a = \left(\begin{array}{cccc}
        1 & 0 & 0 & 0   \\
        0 & 0 & 1 & 0   \\
        0 & 1 & 0 & 0   \\
        0 & 0 & 0 & 1
    \end{array}\right)
    \end{split}
\end{equation}} acts on both the physical and auxiliary systems.
\end{df}

Using this definition for the permutation operator, the lax operator can then be rewritten as

\begin{equation}
    \begin{split}
       \bm{\mathcal{L}}_{n, a} &= u(\mathds{1}_n \otimes \mathds{1}_a) + i \sum_{\alpha} \spin_n^\alpha \otimes \sigma_{a}^\alpha = u(\mathds{1}_n \otimes \mathds{1}_a) + \frac{i}{2} \sum_{\alpha} \sigma_n^\alpha \otimes \sigma_{a}^\alpha \\
       &= u(\mathds{1}_n \otimes \mathds{1}_a) - \frac{i}{2} (\mathds{1}_n \otimes \mathds{1}_a) + \frac{i}{2} (\mathds{1}_n \otimes \mathds{1}_a) + \frac{i}{2} \sum_{\alpha} \sigma_n^\alpha \otimes \sigma_{a}^\alpha \\
       &= \bigg(u-\frac{i}{2}\bigg) (\mathds{1}_n \otimes \mathds{1}_a) + \frac{i}{2} \bigg( \mathds{1}_n \otimes \mathds{1}_a + \sum_{\alpha}\sigma_n^{\alpha}  \otimes \sigma_n^{\alpha} \bigg) \\
       &= \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a} + i \bm{\mathcal{P}}_{n, a}.
       \end{split}
       \label{l-matrix def}
\end{equation}

\blanky \\

\paragraph{\textbf{Fundamental commutation Relations and Monodromy Matrix}}

Consider the following two lax operators

\begin{equation*}
    \begin{array}{c}
        \bl_{n, a_1}(u_1): \blanky \vds_n \otimes \vds_{a_1} \rightarrow \vds_n \otimes \vds_{a_1}  \\
        \\
        \bl_{n, a_2}(u_2): \blanky \vds_n \otimes \vds_{a_2} \rightarrow \vds_n \otimes \vds_{a_2} 
    \end{array} \begin{array}{c}
         \textnormal{both of which act on the physical quantum}\\
         \textnormal{state and on two different auxiliary spaces as well}\footnote{
The permutation operator indeed permutes the factors in the tensor product the factors in the tensor product by calculating the sum of tensor product of the Pauli matrices with respect to the standard four-dimensional basis, ie. if $\x = \left(\begin{array}{c}
     a \\
     b 
\end{array}\right)$ and ${\bf y} = \left(\begin{array}{c}
     c \\
     d 
\end{array}\right)$ then $\x \otimes {\bf y} = \left( \begin{array}{cc}
    ac & ad  \\
    bc & bd 
\end{array} \right)$ and  ${\bf y} \otimes \x = \left( \begin{array}{cc}
    ac & bc  \\
    ad & bd 
\end{array} \right)$. Therefore,

\begin{equation}
    \bm{\mathcal{P}}_{n, a} (\x \otimes {\bf y} ) = {\bf y} \otimes \x \textnormal{ and } \bm{\mathcal{P}}_{n, a} ( {\bf y} \otimes \x) = \x \otimes {\bf y}.
\end{equation}}
. 
    \end{array}
\end{equation*}

The product of these two operator is then a triple tensor product in $\mathds{V}_{n} \otimes \mathds{V}_{a_1} \otimes \mathds{V}_{a_2}$. Now, the following matrix arises 

\begin{df}
Consider an $\bm{\mathcal{R}}$-matrix which relates the permutation and spectral parameters of two auxiliary spaces, which is given by  

\begin{equation}
\begin{array}{c}
     \bm{\mathcal{R}}: \blanky \mathds{V}_{a_1} \otimes \mathds{V}_{a_2} \otimes \mathds{V}_{a_1} \otimes \mathds{V}_{a_2} \\ 
     \\
     \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2) = (u_1-u_2) \mathds{1}_{a_1, a_2} + i \bm{\mathcal{P}}_{a_1, a_2}, \\
     \label{R-matrix def}
\end{array}
\end{equation}
 
which\footnote{Note that $\bm{\mathcal{R}}$ can be rewritten as a $\twobytwo$-matrix in either of the auxiliary spaces, as follows

\begin{equation}
    \bm{\mathcal{R}}_{a1, a2} = \left(\begin{array}{cc}
        \bigg(u + \frac{i}{2}\bigg) \mathds{1}_{a_2} + i \spin_{a_2}^z & i \spin_{a_2}^{-} \\
        i \spin_{a_2}^{+}  & \bigg(u + \frac{i}{2}\bigg) \mathds{1}_{a_2} - i \spin_{a_2}^z 
    \end{array} \right)_{a_1} = \left(\begin{array}{cc}
        \bigg(u + \frac{i}{2}\bigg) \mathds{1}_{a_1} + i \spin_{a_1}^z & i \spin_{a_1}^{-} \\
        i \spin_{a_1}^{+}  & \bigg(u + \frac{i}{2}\bigg) \mathds{1}_{a_1} - i \spin_{a_2}^z 
    \end{array} \right)_{a_2}.
\end{equation}} doesn't act on the physical system at all, but on the auxiliary, phantom, systems.
\end{df}


An interesting relationship between the products of the two lax operators and the $\bm{\mathcal{R}}$-matrix can then be found\footnote{Note that the following permutation properties hold 

\begin{equation}
\bm{\mathcal{P}}_{n, a_1}\bm{\mathcal{P}}_{n, a_2} = \bm{\mathcal{P}}_{a_1, a_2}\bm{\mathcal{P}}_{n, a_1} = \bm{\mathcal{P}}_{n, a_2}\bm{\mathcal{P}}_{a_2, a_1} \textnormal{ and } \bm{\mathcal{P}}_{a, b} = \bm{\mathcal{P}}_{b, a}
\end{equation}

}, consider 

\begin{align*}
    \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2) & \bm{\mathcal{L}}_{n, a_1} (u_1) \bm{\mathcal{L}}_{n, a_2} (u_2) \\ 
    &= {\bigg((u_1-u_2) \mathds{1}_{a_1, a_2} 
    + i \bm{\mathcal{P}}_{a_1, a_2}\bigg)}   \left(\bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} + i \bm{\mathcal{P}}_{n, a_1}\right) \left(\bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_2}\right) \\
    &= \left({(u_1-u_2) \mathds{1}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1}} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_1}} + i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} + i^2 \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1} \right) \\
    & \times \left(\bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_2}\right) \\
    &= {(u_1-u_2) \mathds{1}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1}} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + {(u_1-u_2) \mathds{1}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1}} i \bm{\mathcal{P}}_{n, a_2} \\
    &+ {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_1}} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_1}} i \bm{\mathcal{P}}_{n, a_2} \\ 
    &+ i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg)\mathds{1}_{n, a_1}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    & - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    & = {(u_1-u_2) \mathds{1}_{a_1, a_2}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}} \times \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_2}} \times \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} \\
    &+ {(u_1-u_2) \mathds{1}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}} \times  i \bm{\mathcal{P}}_{n, a_1} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_2}} \times i \bm{\mathcal{P}}_{n, a_1} \\
    &+ i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    & - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    &= \left({(u_1-u_2) \mathds{1}_{a_1, a_2}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_2}}\right) \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} \\ 
    &+ \left({(u_1-u_2) \mathds{1}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_2}} \right) \times  i \bm{\mathcal{P}}_{n, a_1} \\
    &+ i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    & - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    &= \bigg((u_1-u_2) \mathds{1}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + {(u_1-u_2) \mathds{1}_{a_1, a_2} i \bm{\mathcal{P}}_{n, a_2}} \bigg) \left( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_1} \right) \\
    &+ i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{a_1, a_2} \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\
    & - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1}  \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} - \bm{\mathcal{P}}_{a_1, a_2}  \bm{\mathcal{P}}_{n, a_1} i \bm{\mathcal{P}}_{n, a_2} \\\end{align*}
\begin{align*}
    &= \bigg( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}  + { i \bm{\mathcal{P}}_{n, a_2}} \bigg) \left( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_1} \right) (u_1-u_2) \mathds{1}_{a_1, a_2}  \\
    &+ \bigg( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}  + { i \bm{\mathcal{P}}_{n, a_2}} \bigg) \left( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_1} \right)  i \bm{\mathcal{P}}_{n, a_2}  \\
    &= \bigg( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2}  + { i \bm{\mathcal{P}}_{n, a_2}} \bigg) \left( \bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_1} \right) \bigg(\bigg(u-\frac{i}{2}\bigg) \mathds{1}_{n, a_2} + i \bm{\mathcal{P}}_{n, a_2} \bigg), 
\end{align*}

which proves that 

\begin{align}
 & & \alignedbox{\br_{a_1, a_2}(u_1-u_2) \bm{\mathcal{L}}_{n, a_1} (u_1) \bm{\mathcal{L}}_{n, a_2} (u_2)}{= \bm{\mathcal{L}}_{n, a_1} (u_2) \bm{\mathcal{L}}_{n, a_1} (u_1) \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2)}.   
\label{fundamental commutation relation}
\end{align}

From the fundamental commutation relation it can then be shown that the $\bm{\mathcal{R}}$-matrix follows the quantum Yang-Baxter equation. Consider then the product of the following $\bl$-operators,

\begin{equation} 
    \begin{split}
    \bl_{n, 1} \bl_{n, 2} \bl_{n, 3} &= \br_{12}^{-1} \bl_{n, 2} \bl_{n, 1} \bl_{n, 3} \br_{12} \\
    &= \br_{12}^{-1} \br_{13}^{-1} \bl_{n, 2} \bl_{n, 3} \bl_{n, 1} \br_{13}\br_{12} \\
    &= \br_{12}^{-1} \br_{13}^{-1} \br_{23}^{-1} \bl_{n, 3} \bl_{n, 2} \bl_{n, 1} \br_{23}\br_{13} \br_{12} \\
    &= (\br_{23}\br_{13}\br_{12})^{-1} \bl_{n, 3} \bl_{n, 2} \bl_{n, 1}\br_{23}\br_{13}\br_{12},
\end{split}
\end{equation}

and similarly 

\begin{equation}  
    \begin{split}
    \bl_{n, 1} \bl_{n, 2} \bl_{n, 3} &= \br_{23}^{-1} \bl_{n, 1} \bl_{n, 3} \bl_{n, 2} \br_{23} \\
    &= \br_{23}^{-1} \br_{13}^{-1} \bl_{n, 3} \bl_{n, 1} \bl_{n, 2} \br_{13}\br_{23} \\
    &= \br_{23}^{-1} \br_{13}^{-1} \br_{12}^{-1} \bl_{n, 3} \bl_{n, 2} \bl_{n, 1} \br_{12} \br_{13}\br_{23} \\
    &= (\br_{12}\br_{13}\br_{23})^{-1} \bl_{n, 3} \bl_{n, 2} \bl_{n, 1}\br_{12}\br_{13}\br_{23},
\end{split}
\end{equation}

both of which then yield an important constraint on the $\br$-matrix, namely 

\begin{align}
    \alignedbox{\br_{12}\br_{13}\br_{23}}{= \br_{23}\br_{13}\br_{12}},
\end{align}

which is the quantum Yang-Baxter equation. \\

\begin{df}
    Let the monodromy matrix $\bm{\mathcal{T}}_{N,a}$ be defined as a product of subsequent of $\bl$-operators, ie.

\begin{equation}
    \begin{array}{c}
         \bmt_{N,a} = \prod^{j=N}_{1} \bl_{j,a} \\
         \\
         \bmt_{N,a} = \prod^{j=N}_{1} \left(\begin{array}{cc}
            u \mathds{1}_j + i \spin_j^z & i \spin_j^-  \\
            i \spin_j^+ & u \mathds{1}_j - i \spin_j^z
         \end{array}\right) \equiv \left(\begin{array}{cc}
            A(u) & B(u) \\
            C(u) & D(u)
         \end{array}\right) 
    \end{array},
\end{equation}
\end{df}

This matrix obeys the fundamental relation as well\footnote{ For example, consider $N=2$, then

\begin{equation}
    \begin{split}
        {\br_{a_1, a_2}(u_1-u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{T}}_{N, a_2} (u_2)} &= {\br_{a_1, a_2}(u_1-u_2) \bm{\mathcal{T}}_{2, a_1} (u_1) \bm{\mathcal{T}}_{2, a_2} (u_2)} \\
        &= {\br_{a_1, a_2}(u_1-u_2) \bl_{2, a_1} (u_1) \bl_{2, a_1} (u_1) \bl_{2, a_2} (u_2) \bl_{1, a_2} (u_2)} \\
        &= \bigg(\br_{a_1, a_2}(u_1-u_2) \bl_{2, a_1} (u_1) \bl_{2, a_2} (u_2)\bigg) \bl_{1, a_1} (u_1) \bl_{1, a_2} (u_2) \\
        &=  \bl_{2, a_2} (u_2) \bl_{2, a_1} (u_1) \bigg(\br_{a_1, a_2}(u_1-u_2)\bl_{1, a_1} (u_1) \bl_{1, a_2} (u_2) \bigg) \\
        &= \bl_{2, a_2} (u_2) \bl_{2, a_1} (u_1) \bl_{1, a_2} (u_2) \bl_{1, a_1} (u_1) \br_{a_1, a_2}(u_1-u_2) \\
        &=  \bl_{2, a_2} (u_2) \bl_{1, a_2} (u_2) \bl_{2, a_1} (u_1) \bl_{1, a_1} (u_1) \br_{a_1, a_2}(u_1-u_2) \\
        &= \bm{\mathcal{T}}_{n, a_1} (u_2) \bm{\mathcal{T}}_{n, a_1} (u_1) \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2),
    \end{split}
\end{equation}

where the fundamental commutation relation given by \eqref{fundamental commutation relation} was used. Note as well that $\bl$-operators acting on different spaces commute as well, eg. $[\bl_{n_1, a_1}, \bl_{n_2, a_2}] \propto \delta_{n_1, n_2}$. The general fundamental relation can then be proved via mathematical induction for the general case.}, ie.

\begin{align}
 & & \alignedbox{\br_{a_1, a_2}(u_1-u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{T}}_{N, a_2} (u_2)}{= \bm{\mathcal{T}}_{N, a_2} (u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2)}.   
\label{fundamental commutation relation on R}
\end{align}

 \blanky \\

\begin{df}
    The transfer $\mathfrak{t}$-matrix is defined as the $\bm{\mathcal{T}}$-matrix's partial trace over the auxiliary space $\vds_{a}$, ie.

\begin{equation}
    \mathfrak{t}(u) = \Tr_{\vds_{a}} \bm{\mathcal{T}}_{N, a} (u) = \Tr_{\vds_{a}} \left(\begin{array}{cc}
            A(u) & B(u) \\
            C(u) & D(u)
         \end{array}\right)  = A(u) + D(u),
\end{equation}
    where $\mathfrak{t}, A, B, C, D$ all are $\twobytwo$-matrices in the physical system, the auxiliary systems being present no more. 
\end{df}
 
With the previous definitions in mind, \cref{fundamental commutation relation on R}'s double trace can then be written in terms of the transfer matrix, as follows 

\begin{align*}
    \Tr_{\vds_{a_1}} \Tr_{\vds_{a_2}} & \bigg[\br_{a_1, a_2}(u_1-u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{T}}_{N, a_2} (u_2)\bigg] &= \Tr_{\vds_{a_1}} \Tr_{\vds_{a_2}} \bigg[{\bm{\mathcal{T}}_{N, a_1} (u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2)}\bigg] \\
    &\Rightarrow \Tr_{\vds_{a_1}} \Tr_{\vds_{a_2}} \bigg[\br_{a_1, a_2}(u_1-u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{T}}_{N, a_2} (u_2) - {\bm{\mathcal{T}}_{N, a_1} (u_2) \bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2)} \bigg] = 0 \\ 
    &\Rightarrow \Tr_{\vds_{a_1}} \Tr_{\vds_{a_2}} \bigg[\br_{a_1, a_2}(u_1-u_2) \bigg(\bm{\mathcal{T}}_{N, a_1} (u_1) \bm{\mathcal{T}}_{N, a_2} (u_2) - {\bm{\mathcal{T}}_{N, a_2} (u_2) \bm{\mathcal{T}}_{N, a_1} (u_1)\bigg)} \bigg] = 0 \\ 
    \textnormal{ which implies }
    & \mathfrak{t}(u_1)\mathfrak{t}(u_2) = \mathfrak{t}(u_2)\mathfrak{t}(u_1).
\end{align*}

Therefore the transfer matrix commutes with itself for different values of the spectral parameter. It turns out that the monodromy matrix can be expanded in a power series around any point $z_0 \in \mathds{C}$, generating an infinite set of linearly independent commuting operators acting on the full quantum space. This formally leads to the model's integrability. \\

\paragraph{\textbf{Monodromy matrix and the Hamiltonian}}

The Hamiltonian operator belongs to the family of transfer matrices. Let $z_0 = \frac{i}{2}$, then the monodromy matrix can be expanded around said complex point yielding (up to first order)

\begin{equation} 
    \begin{split}
         \bmt_{N,a}(z_0) &= \prod_1^{j=N} \bigg[ \cancel{\bigg(z_0-\frac{i}{2}\bigg) \mathds{1}_{j, a}} + i \bm{\mathcal{P}}_{j, a}\bigg] = i^N \bm{\mathcal{P}}_{N, a} \bm{\mathcal{P}}_{N-1, a} \cdots \bm{\mathcal{P}}_{1, a} = \\
         &= i^N \bm{\mathcal{P}}_{1, 2} \bm{\mathcal{P}}_{2, 3} \cdots \bm{\mathcal{P}}_{N-1, N} \bm{\mathcal{P}}_{N, a}\\
         &= i^N \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1} \bm{\mathcal{P}}_{N, a}
    \end{split}
\end{equation}

where the second line holds given the properties of the permutation operators. Taking the partial trace over the auxiliary space yields the transfer matrix, as follows 

\begin{equation}
    \begin{split}
        \mathfrak{t}(z_0) &= \Tr_{\vds_a}  \bmt_{N,a}(z_0) = \Tr_{\vds_a} i^N \bm{\mathcal{P}}_{1, 2} i^N \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1} \bm{\mathcal{P}}_{N, a} \\
        &= i^N \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1}
        \Tr_{\vds_a} \bm{\mathcal{P}}_{N, a}    = i^N \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1} \Tr_{\vds_a} \frac{1}{2}\left(\begin{array}{cc}
       \mathds{1}_n + \sigma^{z}_{n} &  \sigma^{x}_{n} - i\sigma^{y}_{n} \\
       \sigma^{x}_{n} + i\sigma^{y}_{n}  & \mathds{1}_n - \sigma^{z}_{n} \\
        \end{array}\right)_a. \\
        &= i^N \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1} \mathds{1}_N.
    \end{split}
\end{equation}

Then $\mathcal{U} = i^{-N} \mathfrak{t}(z_0) = \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1}$ is a shift operator in the full quantum Hilbert space $\mathds{H}$. In effect, note that 
$$
 \bm{\mathcal{P}}_{n_1, \blanky n_2} {\bf X}_{n_2} \bm{\mathcal{P}}_{n_1, \blanky n_2} = {\bf X}_{n_1},
$$

ie. this permutation moves ${\bf X}$ one step back. Furthermore, this operator is unitary (given that the permutations are, by definition, unitary operators). Then, according to Stone's theorem on one-parameter unitary groups, the shift operator is related to the momentum operator 

\begin{equation}
    \mathcal{U} = e^{iP}
\end{equation}

\blanky \\

The next order in the expansion of the transfer matrix can then be found via the derivative of the monodromy matrix at $z_0 = \frac{i}{2}$, 

\begin{equation*}
    \begin{split}
    \frac{d \bmt_{N,a}(u)}{du}\bigg|_{u = z_0} &= \frac{d}{du} \prod_{1}^{j=N} \left(\begin{array}{cc}
            u \mathds{1}_j + i \spin_j^z & i \spin_j^-  \\
            i \spin_j^+ & u \mathds{1}_j - i \spin_j^z
         \end{array}\right)\bigg|_{u = z_0} \\
        &=  \frac{d}{du} \left[\left(\begin{array}{cc}
            u \mathds{1}_N + i \spin_N^z & i \spin_N^-  \\
            i \spin_N^+ & u \mathds{1}_N - i \spin_N^z
         \end{array}\right)\right]\bigg|_{u = z_0} \prod_{1}^{j=N-1} \left(\begin{array}{cc}
            u \mathds{1}_j + i \spin_j^z & i \spin_j^-  \\
            i \spin_j^+ & u \mathds{1}_j - i \spin_j^z
         \end{array}\right) \\
         &+ \left(\begin{array}{cc}
            u \mathds{1}_N + i \spin_N^z & i \spin_N^-  \\
            i \spin_N^+ & u \mathds{1}_N - i \spin_N^z
         \end{array}\right) \frac{d}{du} \left[\left(\begin{array}{cc}
            u \mathds{1}_{N-1} + i \spin_{N-1}^z & i \spin_{N-1}^-  \\
            i \spin_{N-1}^+ & u \mathds{1}_{N-1} - i \spin_{N-1}^z
         \end{array}\right)\right]\bigg|_{u = z_0} \\
         &\times \prod_{1}^{j=N-2} \left(\begin{array}{cc}
            u \mathds{1}_j + i \spin_j^z & i \spin_j^-  \\
            i \spin_j^+ & u \mathds{1}_j - i \spin_j^z
         \end{array}\right) \\
         &+ \cdots +  \prod^{j=N}_{3}\left(\begin{array}{cc}
            u \mathds{1}_j + i \spin_j^z & i \spin_j^-  \\
            i \spin_j^+ & u \mathds{1}_j - i \spin_j^z
         \end{array}\right) \frac{d}{du} \left[\left(\begin{array}{cc}
            u \mathds{1}_{2} + i \spin_{2}^z & i \spin_{2}^-  \\
            i \spin_{2}^+ & u \mathds{1}_{2} - i \spin_{2}^z
         \end{array}\right)\right]\bigg|_{u = z_0} \\
         & \times \left(\begin{array}{cc}
            u \mathds{1}_{1} + i \spin_{1}^z & i \spin_{1}^-  \\
            i \spin_{1}^+ & u \mathds{1}_{1} - i \spin_{1}^z
         \end{array}\right)
         \\
         &+ \prod^{j=N}_{2}\left(\begin{array}{cc}
            u \mathds{1}_j + i \spin_j^z & i \spin_j^-  \\
            i \spin_j^+ & u \mathds{1}_j - i \spin_j^z
         \end{array}\right) \frac{d}{du} \left[\left(\begin{array}{cc}
            u \mathds{1}_{1} + i \spin_{1}^z & i \spin_{1}^-  \\
            i \spin_{1}^+ & u \mathds{1}_{1} - i \spin_{1}^z
         \end{array}\right)\right]\bigg|_{u = z_0} s    \end{split} 
\end{equation*}
\begin{equation*}
    \begin{split}
         &= i^{N-1} \bigg[ \prod_{1}^{j=N-1} \bm{\mathcal{P}}_{j} + \prod^{j=N}_{N} \bm{\mathcal{P}}_{j}\times  \prod_{1}^{j=N-2} \bm{\mathcal{P}}_{j} + \cdots + \prod^{j=N}_{k} \bm{\mathcal{P}}_{j}\times  \prod^{k+2}_{1} \bm{\mathcal{P}}_{j} \\
         &+ \cdots + \prod^{j=N}_{3} \bm{\mathcal{P}}_{j} \times \prod^{j=1}_{1} \bm{\mathcal{P}}_{j} + \prod^{j=N}_{2} \bm{\mathcal{P}}_{j} \bigg] \\
         &= i^{N-1} \sum_{n \in \mathds{N}} \bm{\mathcal{P}}_{N, a} \cdots \bm{\mathcal{P}}_{n-1, a} \bm{\mathcal{P}}_{n+1, a} \cdots \bm{\mathcal{P}}_{1, a} \\ 
        &= i^{N-1} \sum_{n \in \mathds{N}} \bm{\mathcal{P}}_{1, 2} \bm{\mathcal{P}}_{2, 3}\cdots \bm{\mathcal{P}}_{n-1, n+1}
         \cdots \bm{\mathcal{P}}_{N-1, N} \bm{\mathcal{P}}_{N, a} \\
         &= i^{N-1} \sum_{n \in \mathds{N}} \prod_{j=1}^{n-2} \bm{\mathcal{P}}_{j, \blanky j+1}  \times \bm{\mathcal{P}}_{n-1, \blanky n+1} \times \prod_{j=n+2}^{N-1}  \bm{\mathcal{P}}_{j, \blanky j+1} \bm{\mathcal{P}}_{N, a}.
    \end{split} 
\end{equation*}

Therefore,

\begin{equation}
    \begin{split}
        \frac{d \mathfrak{t}(u)}{du}\bigg|_{u = z_0} &= \frac{d \Tr_{\vds_{a}} \bmt_{N,a}(u)}{du}\bigg|_{u = z_0} \\
        &= i^{N-1} \sum_{n \in \mathds{N}} \prod_{j=1}^{n-2} \bm{\mathcal{P}}_{j, \blanky j+1} 
        \times \bm{\mathcal{P}}_{n-1, \blanky n+1} \times \prod_{j=n+2}^{N-1}  \bm{\mathcal{P}}_{j, \blanky j+1} \times \Tr_{\vds_{a}} \bm{\mathcal{P}}_{N, a} \\
        &= i^{N-1} \sum_{n \in \mathds{N}} \prod_{j=1}^{n-2} \bm{\mathcal{P}}_{j, \blanky j+1} 
        \times \bm{\mathcal{P}}_{n-1, \blanky n+1} \times \prod_{j=n+2}^{N-1}  \bm{\mathcal{P}}_{j, \blanky j+1}.
    \end{split}
\end{equation}

Now, note that 

\begin{equation}
    \begin{split}
        \frac{d}{du} \log(\mathfrak{t}(u))\bigg|_{u = z_0} &= \frac{d}{du} \log \Tr_{\vds_{a}} \bm{\mathcal{T}}(u) \bigg|_{u=z_0} \\
        &= \frac{d}{du}\bigg(\mathfrak{t}(u)\bigg) \mathfrak{t}(u)^{-1}\bigg|_{u = z_0} \\
        &= i^{N-1} \sum_{n \in \mathds{N}} \bigg( \prod_{j=1}^{n-2} \bm{\mathcal{P}}_{j, \blanky j+1} 
        \times \bm{\mathcal{P}}_{n-1, \blanky n+1} \times \prod_{j=n+2}^{N-1}  \bm{\mathcal{P}}_{j, \blanky j+1} \bigg) \times \bigg(i^N \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{j, \blanky j+1} \mathds{1}_N\bigg)^{-1} \\
        &= \frac{1}{i} \sum_{n \in \mathds{N}} \bigg(\prod_{j=1}^{n-2} \bm{\mathcal{P}}_{j, \blanky j+1} 
        \times \bm{\mathcal{P}}_{n-1, \blanky n+1} \times \prod_{j=n+2}^{N-1}  \bm{\mathcal{P}}_{j, \blanky j+1} \bigg) \times \prod_{j=1}^{N-1} \bm{\mathcal{P}}_{N-1-j, N-j}^{-1} \\
        &= \frac{1}{i} \sum_{n \in \mathds{N}} \bigg(\prod_{j=1}^{n-2} \bm{\mathcal{P}}_{j, \blanky j+1} 
        \times \bm{\mathcal{P}}_{n-1, \blanky n+1} \times \prod_{j=n+2}^{N-1}  \bm{\mathcal{P}}_{j, \blanky j+1} \bigg) \times \prod_{1}^{j = N-1} \bm{\mathcal{P}}_{j, j+1}  \\
        &= \frac{1}{i} \sum_{n \in \mathds{N}} \bigg(\cancel{\bm{\mathcal{P}}_{1,2}} \cancel{\bm{\mathcal{P}}_{2,3}} \cdots \bm{\mathcal{P}}_{n-1, \blanky n+1} \cdots \cancel{\bm{\mathcal{P}}_{N-1,N} \times \bm{\mathcal{P}}_{N-1, \blanky N}} \cdots \bm{\mathcal{P}}_{n,\blanky n+1} \cdots \cancel{\bm{\mathcal{P}}_{2,3}} \cancel{\bm{\mathcal{P}}_{1,2}}\bigg) \\
        &= \frac{1}{i}  \sum_{n \in \mathds{N}} \bm{\mathcal{P}}_{N-1, \blanky N}
    \end{split}
\end{equation}

Note that \eqref{XXX model} can be rewritten in terms of the permutation operator as 

\begin{equation}
    {\bf H} = \frac{J}{2} \sum_{n}\bigg( \bm{\mathcal{P}}_{n, \blanky n+1} - \mathds{1}^{\otimes N}\bigg),
\end{equation}

which in turn can be rewritten as 

\begin{align}
    \alignedbox{{\bf H}}{ = \frac{J}{2} \bigg(i \frac{d}{du} \log(\mathfrak{t}(u))\bigg|_{u=z_0} - N \mathds{1}^{\otimes N}\bigg)},
    \label{Hamiltonian monodromy}
\end{align}

which shows that the XXX Hamiltonian belongs to the family of $N-1$ commuting operators generated by the trace of the monodromy matrix $\bmt$. As a result, the Hamiltonian commutes with the transfer matrix $ [{\bf H}, \mathfrak{t}(u)] = 0.$ \\

\paragraph{\textbf{Diagonalizing the Hamiltonian}}

The only task left is to diagonalize the Hamiltonian, by diagonalizing the transfer matrix. The monodromy matrix ${\mathfrak{t}}_{N,a}$ is a $\twobytwo$-matrix in the physical space $\vds_{a}$. Recalling the fundamental commutation relation between the $\bm{\mathcal{R}}$ and $\bm{\mathcal{T}}$-matrices, then the following theorem holds,

\begin{theo} \label{theo monodromy}
Let $\bm{\mathcal{T}}$ be the monodromy matrix for the Heisenberg model. Then, $\forall u_1, u_2 \in \mathds{C}$ then \\

\begin{itemize}
    \item $[\bm{\mathcal{T}}_{ij}(u_1), \bm{\mathcal{T}}_{ij}(u_2)] = 0, \blanky i,j = 1, 2$, which entails that $[B(u_1), B(u_2)] = \cdots = [D(u_1), D(u_2)] = 0$ \\
    \item $A(u_1) B(u_2) = f(u_1-u_2) B(u_2) A(u_1) + g(u_1-u_2) B(u_1)A(u_2)$\\
    \item $D(u_1) B(u_2) = h(u_1-u_2) B(u_2) D(u_1) + k(u_1-u_2) B(u_1)D(u_2)$,
\end{itemize}

where $f,g,h,$ and $k$ are given by 

\begin{align*}
    f(u) &= \frac{u-i}{u}, & g(u) &= \frac{i}{u}, & h(u) &= \frac{u + i}{u}, & k(u) &= -\frac{i}{u}.
\end{align*}
\end{theo}

\begin{proof}
Consider two different monodromy matrices, labelled $\bm{\mathcal{T}}_{N, a_1} (u_1)$ and  $\bm{\mathcal{T}}_{N, a_2} (u_2)$, acting on two different auxiliary spaces, labelled $\vds_1$ and $\vds_2$ respectively. Then, these $\bmt$-matrices can be written as 

\begin{equation} \begin{array}{cc}
   \bm{\mathcal{T}}_{N, a_1} (u_1) = \left( \begin{array}{cc}
        A(u_1) & B(u_1)  \\
        C(u_1) & D(u_1) 
    \end{array} \right) \otimes \mathds{1}_{\vds_2}, & \bm{\mathcal{T}}_{N, a_2} (u_2) = \mathds{1}_{\vds_1} \otimes \left( \begin{array}{cc}
        A(u_2) & B(u_2)  \\
        C(u_2) & D(u_2) 
    \end{array} \right) \\
    = \left( \begin{array}{cccc}
        A(u_1) & 0 & B(u_1) & 0  \\
        0 & A(u_1) & 0 & B(u_1) \\
        C(u_1) & 0 & D(u_1) & 0  \\
        0 & C(u_1) & 0 & D(u_1) \\
    \end{array} \right), & \left( \begin{array}{cccc}
        A(u_2) & B(u_2) & 0 & 0  \\
        C(u_2) & D(u_2) & 0 & 0 \\
        0 & 0 & A(u_2) & B(u_2) \\
        0 & 0 & C(u_2) & D(u_2) \\
    \end{array} \right)
\end{array}
\end{equation}

 Recall that the $\bm{\mathcal{R}}$-matrix is given by \eqref{R-matrix def}, which can be rewritten as 

$$
\bm{\mathcal{R}}_{a_1, a_2}(u_1-u_2) = 
\left(\begin{array}{cccc}
        a (u_1-u_2) & 0 & 0 & 0  \\
        0 & b(u_1-u_2) & c(u_1-u_2) & 0  \\
        0 & c(u_1-u_2) & b(u_1-u_2) & 0 ) \\
        0 & 0 & 0 & a (u_1-u_2) \\
    \end{array} \right) \textnormal{ where } \begin{array}{c}
         a(\lambda) = \lambda + i  \\
         b(\lambda) = \lambda \\
         c(\lambda) = i 
    \end{array}, 
$$

Then the fundamental commutation relation \eqref{fundamental commutation relation on R} establishes a relationship between the monodromy $\bmt$-matrices and the $\bm{\mathcal{R}}$-matrix. Then, plugging in the previous results yields

\begin{equation*}
    \Rightarrow \begin{split}
    \left(\begin{array}{cccc}
        a_{12} & 0 & 0 & 0  \\
        0 & b_{12} & c_{12} & 0  \\
        0 & c_{12} & b_{12} & 0  \\
        0 & 0 & 0 & a_{12} \\
    \end{array} \right) \left( \begin{array}{cccc}
        A(u_1) A(u_2) & A(u_1) B(u_2) & B(u_1) A(u_2) & B(u_1) B(u_2)  \\
        A(u_1) C(u_2) & A(u_1) D(u_2) & B(u_1) C(u_2) & B(u_1) D(u_2) \\
        C(u_1) A(u_2) & C(u_1) B(u_2) & D(u_1) A(u_2) & D(u_1) B(u_2) \\
        C(u_1) C(u_2) & C(u_1) D(u_2) & D(u_1) C(u_2) & D(u_1) D(u_2) \\
    \end{array} \right) \\ = \left( \begin{array}{cccc}
        A(u_2) A(u_1) & B(u_2)A(u_1) & A(u_2) B(u_1) & B(u_2) B(u_1)  \\
        C(u_2) A(u_1) & D(u_2) A(u_1) & C(u_2) B(u_1) & D(u_2) B(u_1) \\ 
        A(u_2) C(u_1) & B(u_2) C(u_1) & A(u_2) D(u_1) & B(u_2) D(u_1) \\ 
        C(u_2) C(u_1) & D(u_2) C(u_1) & C(u_2) D(u_1) & D(u_2) D(u_1) 
    \end{array} \right) \left(\begin{array}{cccc}
        a_{12} & 0 & 0 & 0  \\
        0 & b_{12} & c_{12} & 0  \\
        0 & c_{12} & b_{12} & 0  \\
        0 & 0 & 0 & a_{12} \\
    \end{array} \right) \\
   \Rightarrow 
   \left(\begin{array}{cccc}
        a_{12} A_1 A_2 & a_{12} A_1 B_2 & a_{12} B_1 A_2 & a_{12} B_1 B_2 \\
        b_{12} A_1 C_2 + c_{12} C_1 A_2 & b_{12} A_1 D_2 + c_{12} C_1 B_2 & b_{12} B_1 C_2 + c_{12} D_1 A_2 & b_{12} B_1 D_2 + c_{12} D_1 B_2 \\
        c_{12} A_1 C_2 + b_{12} C_1 A_2 & b_{12} A_1 D_2 + c_{12} C_1 B_2 & c_{12} B_1 C_2 + b_{12} D_1 A_2 & c_{12} B_1 D_2 + b_{12} D_1 B_2 \\
        a_{12} C_1 C_2 & a_{12} C_1 D_2 & a_{12} D_1 C_2 & a_{12} D_1 D_2
    \end{array} \right) \\
    = \left(\begin{array}{cccc}
        a_{12} A_2 A_1 & b_{12} B_2 A_1 + c_{12} A_2 B_1 & c_{12} B_2 A_1 + b_{12} A_2 B_1 & a_{12} B_2 B_1\\ 
        a_{12} C_2 A_1 & b_{12} D_2 A_1 + c_{12} C_2 B_1 & c_{12} D_2 A_1 + b_{12} C_2 B_1 & a_{12} D_2 B_1\\
        a_{12} A_2 C_1 & b_{12} B_2 C_1 + c_{12} A_2 D_1 & c_{12} B_2 C_1 + b_{12} A_2 D_1 & a_{12} B_2 D_1\\
        a_{12} C_2 C_1 & b_{12} D_2 C_1 + c_{12} C_2 D_1 & c_{12} D_2 C_1 + b_{12} C_2 D_1 & a_{12} D_2 D_1
    \end{array} \right)
    \end{split}
\end{equation*}

\[
    \Rightarrow \text{\small $ \left(  \scalemath{0.7}{\begin{array}{cccc}
    a_{12} [A_1, A_2] & a_{12} A_1 B_2 - (b_{12} B_2 A_1 + c_{12} A_2 B_1) & a_{12} B_1 A_2 - (c_{12} B_2 A_1 + c_{12} A_2 B_1) & a_{12} [B_1, B_2]  \\
    (b_{12} A_1 C_2 + c_{12} C_1 A_2) - a_{12} C_2 A_1 & b_{12} [A_1, D_2] + c_{12} [C_1 B_2] & (b_{12} [B_1, C_2] + c_{12} [D_1, A_2] & b_{12} B_1 D_2 + c_{12} D_1 B_2 - a_{12} D_2 B_1 \\
    c_{12} A_1 C_2 + b_{12} C_1 A_2 - a_{12} A_2 C_1 & (b_{12} A_1 D_2 + c_{12} C_1 B_2) - b_{12} B_2 C_1 + c_{12} A_2 D_1) & c_{12} [B_1, C_2] + b_{12} [D_1, A_2] & c_{12} B_1 D_2 + b_{12} D_1 B_2 - a_{12} B_2 D_1 \\
    a_{12} [C_1, C_2] & a_{12} C_1 D_2 - (b_{12} D_2 C_1 + c_{12} C_2 D_1) & a_{12} D_1 C_2 - (c_{12} D_2 C_1 + b_{12} C_2 D_1) & a_{12} [D_1, D_2]
    \end{array}} \right) = {\bf 0} $},
\]

from which, it's been proven that $[\bm{\mathcal{T}}_{ij}(u_1), \bm{\mathcal{T}}_{ij}(u_2)] = 0, \blanky i,j = 1, 2$ as long as $a (u_1 - u_2) \neq 0$. From the other matrix-entries, it's immediately seen that 

$$
a(u_1-u_2) B(u_1) A(u_2) = c(u_1-u_2) B(u_2) A(u_1) + b(u_1-u_2) A(u_2) B(u_1).  
$$

Swapping $u_1 \rightarrow u_2$ implies $u_1 - u_2 \rightarrow -(u_1 - u_2)$. Now, note that $c(u_1)/b(u_1) = g(u_1) = g(-u_1)$ and similarly $a(-u_1)/b(-u_1) = h(-u_1) \equiv f(u_1)$, which yields the second line of theorem \ref{theo monodromy}. The third claim can then be similarly derived. 

\end{proof} 

\blanky \\

\paragraph{\textbf{Eigenvalues of the Bethe Ansatz}}

Theorem \ref{theo monodromy}'s relations shows the model's inner structure, identifying an underlying algebraic structure somewhat similar to that of the Harmonic oscillator, where $A+D$ are associated with the eigenenergies, and where $B$ and $C$ can be interpreted as ladder operators. \\

Then, a Fock-like state space can be constructed for the $N$-body system, with its ground state satisfying $C \Omega^{\otimes N} = 0$. Then, $\omega_+^{i} = \left( \begin{array}{cc}
    1 & 0 
\end{array}\right)_{i}^{\dagger}$ describes $i$-th spin's state, with up spin. Then, 

$$
\spin^{+} \omega_+^{i} = 0,
$$

Therefore, consider the $\bl$-matrix, defined by \eqref{l-matrix def}, its action on a tensor product of states can be written out as 

\begin{equation}
    \bl_{N, a} v \otimes \omega_+^{i} \left(\begin{array}{cc}
        \lambda + \frac{i}{2} & \cdots \\
        0 &  \lambda - \frac{i}{2}
    \end{array}\right) v \otimes \omega_+^{i}, \blanky \forall v \in \mathds{V}_a,
\end{equation}

since $\spin^{+}$ annihilates $\omega_+^i$. Thus, the ground sate can be written as the physical ferromagnetic vacuum state with all its spins up. Said state is an eigenstate of $A(u)$ and $D(u)$ and is annihilated by $C(u)$, ie. 

\begin{align}
    \Omega^{\otimes N} = \bigotimes_{i=1}^{N} \left( \begin{array}{c} 
         1 \\
         0 
    \end{array} \right), \textnormal{ where } \begin{array}{c}
    A(u) \Omega^{\otimes N} = \bigg(u + \frac{i}{2}\bigg)^{N} \Omega^{\otimes N}, \\
    \\
    D(u) \Omega^{\otimes N} = \bigg(u - \frac{i}{2}\bigg)^{N} \Omega^{\otimes N}, \\
    \end{array}
    C(u) \Omega^{\otimes N} = 0. 
\end{align}

The $B(u)$ operators can then be used to construct the Bethe state

\begin{equation}
    \ket{u_1, \cdots u_M} = \prod_{j=1}^{M < N} B(u_j) \Omega^{\otimes N}, \textnormal{ for some set } \{u_j\}_{j=1}^{M < N} \subset \mathds{C}.
    \label{bethe state}
\end{equation}

A priori, not all complex-valued sequences are allowed since the Bethe states must be eigenvectors of $A(u) + D(u)$, which yields some algebraic conditions. \\

\paragraph{\textbf{Conditions on } $\{u_j\}_{j=1}^{M < N}$}

Consider the Bethe state given by \cref{bethe state}. Then, 

\begin{equation*}
    A(v) \ket{u_1, \cdots u_M} = A(v) \prod_{j=1}^{M < N} B(u_j) \Omega^{\otimes N}.
\end{equation*}

Using the fundamental commutation relations given \cref{theo monodromy},

$$
    A(v) B(u) = f(v-u) B(u) A(v) + g(v-u) B(v) A(u).
$$

Therefore,

\begin{equation}
    \begin{split}
        A(v) \ket{u_1, \cdots u_M} &= \bigg[f(v-u_1) B(u_1) A(v) + g(v-u_1) B(v) A(u_1)\bigg] \prod_{j=2}^{M < N} B(u_j) \Omega^{\otimes N} \\
        &= \left[\prod_{k=1}^{\ell} f(v-u_k)\right] \alpha^N(v) \ket{u_1, \cdots u_M} + \mathcal{O}({A \times D}),
    \end{split}
\end{equation}

wherein, the first term is an scalar times the Bethe state, said scalar being the eigenvalue if and only if the second term, the term with products of $A$ and $D$, cancels out. In that case, the Bethe state is an eigenvector of $A + D$. Then, continuing the previous calculation 

\begin{equation}
    \begin{split}
         A(v) \ket{u_1, \cdots u_M} &=  \bigg[f(v-u_1) B(u_1) A(v) + g(v-u_1) B(v) A(u_1)\bigg] B(u_2) \prod_{j=3}^{M < N} B(u_j) \Omega^{\otimes N} \\
         &= \bigg[f(v-u_1)f(v-u_2) B(u_1) B(u_2) A(v) + f(v-u_1)g(v-u_2) B(u_1) B(v) A(u_2) \\
         & + g(v-u_1)f(u_1-u_2) B(v) B(u_2) A(u_1) + g(v-u_1)g(v-u_2) B(v) B(u_2)
         \bigg] \prod_{j=3}^{M < N} B(u_j) \Omega^{\otimes N}. 
    \end{split}
\end{equation}

Now, note that 

\begin{align*}
    %\begin{split}
        \bigg(A(v) + D(v) \bigg)\ket{u_1, \cdots u_M} &= \bigg[\bigg(\prod_{k=1}^{\ell} f(v-u_k)\bigg)\alpha^N(v) + \bigg(\prod_{k=1}^{\ell} h(v-u_k)\bigg) \delta^N(v) \bigg] \ket{u_1, \cdots u_M} \\
        &+ \sum_{k=1}^{\ell} \bigg[\bigg(g(v-u_k) \bigg[ \prod_{j \neq k}^{\ell} f(u_k - u_j)\bigg] \alpha^N(u_k)\bigg) + h(v-u_k) \bigg(\prod_{j \neq k}^{\ell} h(u_k - u_j)\bigg) \delta^N(u_j) \\
        &\times \prod_{\substack{j = 1 \\
                                 j \neq k}}^{\ell} \Omega^{\otimes N} B(u_i)\bigg]\\
    &\equiv \bigg[\bigg(\prod_{k=1}^{\ell} f(v-u_k)\bigg)\alpha^N(v) + \bigg(\prod_{k=1}^{\ell} h(v-u_k)\bigg) \delta^N(v) \bigg] \ket{u_1, \cdots u_M} + 0
    %\end{split} 
\end{align*}

\begin{align*}
    \Rightarrow \sum_{k=1}^{\ell} \bigg[\bigg(g(v-u_k) \bigg[ \prod_{j \neq k}^{\ell} f(u_k - u_j)\bigg] \alpha^N(u_k)\bigg) + h(v-u_k) \bigg(\prod_{j \neq k}^{\ell} h(u_k - u_j)\bigg)  \delta^N(u_j) \bigg] &= 0 \\
    \sum_{k=1}^{\ell} \bigg[\bigg(g(v-u_k) \bigg[ \prod_{j \neq k}^{\ell} f(u_k - u_j)\bigg] \alpha^N(u_k)\bigg) - g(v-u_k) \bigg(\prod_{j \neq k}^{\ell} h(u_k - u_j)\bigg)  \delta^N(u_j) \bigg] &= 0 \\
    \sum_{k=1}^{\ell} g(v-u_k) \bigg[ \prod_{j \neq k}^{\ell} f(u_k - u_j)\bigg] \alpha^N(u_k) + \prod_{j \neq k}^{\ell} h(u_k - u_j) \delta^N(u_j) \bigg] &= 0,
\end{align*}

which must be true for all $k$,

\begin{align}
    & & \bigg[\prod_{j \neq k}^{\ell} f(v- u_k)\bigg] \alpha^N(u_j) = \bigg[\prod_{j \neq k}^{\ell} h(v - u_k) \bigg]  \delta^N(u_j).
\end{align}

Now using \cref{theo monodromy} functions and the that $\alpha(u) = u + \frac{i}{2}$ and $\delta(u) = u - \frac{i}{2}$, the previous equation can be rewritten as 

\begin{equation}
    \begin{split}
        \bigg[\prod_{j \neq k}^{\ell} &f(u_k - u_j)\bigg] \alpha^N(u_j) = \bigg[\prod_{j \neq k}^{\ell} h(u_k - u_j) \bigg]  \delta^N(u_j) \\
        \prod_{j \neq k}^{\ell} &\frac{u_k - u_j - i}{u_k - u_j} \bigg(u_j + \frac{i}{2}\bigg) = \prod_{j \neq k}^{\ell} \frac{u_k - u_j + i}{u_k - u_j} \bigg(u_j - \frac{i}{2}\bigg)\\
        0 &= \prod_{j \neq k}^{\ell} \frac{u_k - u_j - i}{u_k - u_j} \bigg(u_j + \frac{i}{2}\bigg) - \prod_{j \neq k}^{\ell} \frac{u_k - u_j + i}{u_k - u_j} \bigg(u_j - \frac{i}{2}\bigg),
    \end{split}
\end{equation}

which can be rearranged to yield the Bethe ansatz equations, 

\begin{align}
    \alignedbox{\left(\frac{u_k+\frac{i}{2}}{u_k - \frac{i}{2}}\right)^N}{= \prod_{j\neq k}^{\ell} \frac{u_k - u_j + i}{ u_k - u_j -i}},
    \label{Bethe coeff equations}
\end{align}

which is a set of $\ell$ non linear equations on the coefficients $u_k \in \mathds{C}$. \\

\paragraph{\textbf{Momentum and Energy}}

Let $\{u_k\}_{k=1}^{\ell < N} \subset \mathds{C}$ satisfy the Bethe equations. Then,  

\begin{equation}
\begin{split}
    (A(v) + D(v)) \ket{u_1, \cdots u_M} &= \bigg[\bigg(\prod_{k=1}^{\ell} f(v-u_k)\bigg)\alpha^N(v) + \bigg(\prod_{k=1}^{\ell} h(v-u_k)\bigg) \delta^N(v) \bigg] \ket{u_1, \cdots u_M} \\
    (A(v) + D(v)) \ket{u_1, \cdots u_M} &= \bigg[ \left(v + \frac{i}{2}\right)^N \prod_{k=1}^{\ell} \frac{v - u_k - i}{v-u_k} + \left(v - \frac{i}{2}\right)^N \prod_{k=1}^{\ell} \frac{v - u_k + i}{v-u_k} \bigg]\ket{u_1, \cdots u_M} \\
    \left(A\left(\frac{i}{2}\right) + D\left(\frac{i}{2}\right)\right) \ket{u_1, \cdots u_M} &= i^N \prod_{k=1}^{\ell} \frac{u_k + \frac{i}{2}}{u_k - \frac{i}{2}} \ket{u_1, \cdots u_M} \equiv \lambda(\{u_k\}_{k=1}^{\ell < N})\ket{u_1, \cdots u_M}
\end{split}
\end{equation}

Therefore, via the transfer matrix, it holds that $U = e^{iP} = i^{-N} \mathfrak{t}\left(\frac{i}{2}\right) = i^{-N} \left(A\left(\frac{i}{2}\right) + D\left(\frac{i}{2}\right) \right)$, from which 

\begin{equation}
    P \ket{u_1, \cdots u_\ell} = \sum_{k=1}^{\ell} p(u_k) \ket{u_1, \cdots u_\ell} \textnormal{ where } p(u_k) = \frac{1}{i} \log \frac{u_k + \frac{i}{2}}{u_k - \frac{i}{2}}.
\end{equation}

Now, \cref{Hamiltonian monodromy} establishes that the XXX Hamiltonian belongs to the monodromy matrices' family. Furthermore, it provides a link between the $A+D$'s eigenvalues and the eigenenergies. In effect, said eigenenergies may be found by differentiating the $A+D$'s eigenvalues over $u$ and setting $u = z_0 = \frac{i}{2}$. Let the former 

$$
\Lambda(v) = \left(v + \frac{i}{2}\right)^N \prod_{k=1}^{\ell} \frac{v - u_k - i}{v-u_k} + \left(v - \frac{i}{2}\right)^N \prod_{k=1}^{\ell} \frac{v - u_k + i}{v-u_k},
$$

then, 

\begin{align*}
    \frac{d \log \Lambda(v)}{dv} \bigg|_{v=z_0} &= \frac{1}{\Lambda(v)} \frac{d \Lambda(v)}{dv} \bigg|_{v=z_0} \\
    &= \frac{1}{\Lambda(v)\bigg|_{v=z_0}} \bigg[N i^{N-1} \prod_{k=1}^{\ell} \frac{-u_k - \frac{i}{2}}{\frac{i}{2} - u_k} + i^N \sum_k \frac{i}{(\frac{i}{2} - u_k)^2} \prod_{\substack{j=1 \\
                      j \neq k}}^{\ell} \frac{-u_j - \frac{i}{2}}{\frac{i}{2} - u} \bigg] \\
    &= i \bigg(\sum_{k=1}^{\ell} \frac{1}{u_k^2 + \frac{1}{4}} - N\bigg).
\end{align*}

Then, using \cref{Hamiltonian monodromy}, yields the eigenenergies

\begin{equation}
    H \ket{u_1, \cdots u_M} = \left[ \frac{i}{2} i \bigg(\sum_{k=1}^{\ell} \frac{1}{u_k^2 + \frac{1}{4}} - N\bigg) - \frac{N}{2} \right] \ket{u_1, \cdots u_M} \\
\end{equation}

or, equivalently, 

\begin{align}
    \alignedbox{{\bf H} \ket{u_1, \cdots u_M}}{= \sum_{k =1}^{\ell} \epsilon(u_k) \ket{u_1, \cdots u_M} \textnormal{ where } \epsilon(u_k) = - \frac{1}{2} \frac{1}{u_k^2 + \frac{1}{4}}},
\end{align}

which concludes the Bethe solution for the XXX Heisenberg chain.

\clearpage 


\subsection{Numerical solution to Fermionic models}

Consider a Hamiltonian describing a fermionic system, given by 

\begin{equation}
    {\bf H} = J \summation (f_{j}^{\dagger}f_{j+1} + f_{j+1}^{\dagger}f_{j}) + \sum_{j=1} \lambda_j f_{j}^{\dagger} f_j, \begin{array}{c}
         \textnormal{with the usual } \\
         \textnormal{ conmutation rules} 
    \end{array}
    \begin{array}{c}
         \{f_j, f_k\} = \{f_j^\dagger, f_k^\dagger\} = 0  \\
         \{f_j, f_k^\dagger\} = \delta_{jk}
    \end{array}
    \label{fermionic hamiltonian}
\end{equation}

where $L$ indicates the number of lattice sites, $J$ is the hopping strength, which could be either positive or negative, and where $\lambda_j$ is the on-site potential strength\footnote{The $\lambda_j$-term frequently appears in many condensed matter models, with different numerical values and interpretations, eg.

\begin{itemize}
    \item In the XX model, $\lambda_j = \lambda \blanky \forall j$. 
    \item While for the Anderson model $\lambda_j \in \mathcal{U}_{\R_{[-W, W]}}$, a uniform random variable, with $W$ being the disorder strength. 
    \item In the Aubry-André model, $\lambda_j = \lambda \cos(2\pi\sigma j)$, with $\sigma \in \mathds{I}$ and $\lambda$ quantifying the disorder strength. 
\end{itemize}}. Said Hamiltonian has open boundaries conditions since there is no hopping term across the boundary. Note that we can rewrite \eqref{fermionic hamiltonian} as 

\begin{equation}
    {\bf H} = \sum_{i, j = 1}^{L} \M_{ij} f_i^{\dagger} f_j \textnormal{ with } \begin{array}{c}
         \M \in \textnormal{GL}(L, \R), \\
         \M_{ij} = \left\{\begin{array}{cc}
             \lambda_i & \textnormal{ if } i=j  \\
              J & \textnormal{ if } j=i+1 \textnormal{ or } i = j + 1 \\
              0 & \textnormal{ otherwise}
         \end{array} \right.
    \end{array},
\end{equation}

which is a positive-defined tri-diagonal matrix.
Let ${\bf f} = (f_1 \blanky f_2 \blanky \cdots f_L)\transpose$ be a vector of the $L$ fermionic operators. Then, \eqref{fermionic hamiltonian} can be rewritten as 

\begin{align}
    {\bf H} = {\bf f}^\dagger \M {\bf f}.
\end{align}

Since $\M$ is symmetric, then it can be diagonalized  $\M = A \mathcal{D} A\transpose$, where $A \in \mathds{R}^{L \times L}$ is a real orthogonal matrix and with $\mathcal{D}_{ij} \in \mathds{R}^{L \times L} \blanky | \blanky \mathcal{D}_{ij}  = \epsilon_i \delta_{ij}$. In this context, the $A$-matrix acts on the fermionic operator as a Bogoliubov transformation, allowing for \eqref{fermionic hamiltonian} to be rewritten as 

\begin{equation}
     {\bf H} = {\bf f}^\dagger A \mathcal{D} A\transpose {\bf f} = {\bf d}^\dagger \mathcal{D} {\bf d}
     \label{fermionic matrix hamiltonian}
\end{equation}

where ${\bf d} = A\transpose {\bf f}$. Since the $A$-matrix is orthogonal, the new $d_k$-operators are fermionic operators as well, satisfying \eqref{fermionic hamiltonian}'s anti-commutation rules. Then, the new fermionic operators are 

\begin{equation*}
    \begin{array}{c}
         d_k = \sum_{j=1}^{L} A_{jk} f_j  \\ 
         \\
         f_j = \sum_{k=1}^{L} A_{jk} d_k 
    \end{array} \textnormal{ since } A\transpose A = \sum_{j,k = 1}^{L} A_{jk} A_{kj} = \mathds{1}_{L}.
\end{equation*}

Then, we can expand \eqref{fermionic matrix hamiltonian} in terms of the lattices, as follows 

\begin{equation}
    {\bf H} = \sum_{k = 1}^{L} \epsilon_k d_k^\dagger d_k,
\end{equation}

which is a sum of number operators with potentials. The eigenstates can then be constructed from the the theory's vacuum state, by applying the $d_k^{\dagger}$-fermionic operators. In the Heisenberg-picture, the $d_k$-operators can be evolved via the Heisenberg equation of motion

\begin{equation}
\frac{d}{dt} d_k = i [{\bf H}, d_k],
\label{H eom}
\end{equation}

and using that $d_k^2 = 0$, it turns out that \eqref{H eom}'s solution is simply $d_k(t) = e^{-i\epsilon_k t} d_k$. The system's correlation can be easily found by analyzing the following matrix. Let $\mathcal{N}_{jk} = \langle d_j^\dagger d_k \rangle$, where the expectation value is taken via calculating the operator's trace along the Fock space, which takes the following values 

\begin{equation}
    \mathcal{N}_{jk} = \langle d_j^\dagger d_k \rangle = \left\{\begin{array}{c}
        0 \textnormal{ or } 1 \textnormal{ if } j=k  \\
        0 \textnormal{ if } j \neq k 
    \end{array} \right.,
\end{equation}

ie. different lattice-sites are not correlated and there can only be a single fermion at most per lattice site, in accordance with Pauli's principle. A ground state, for example, would choose to turn on all fermions in the eigenmode $d$-space such that $\epsilon_k < 0$. If instead, the expectation value is taken with thermal states, the Fermi-Dirac distribution is returned, 

\begin{equation}
    \mathcal{N}_{jk} = \langle d_j^\dagger d_k \rangle_{\textnormal{th}} =  \frac{1}{1+e^{\beta \epsilon_k + \mu}} \delta_{jk}.
\end{equation}

Another interesting quality is a system with an initial configuration where the system's initial state, in real space, is known. In this setting, $\mathcal{N}_{jk}$ is known for all lattices. Consider for example the Anderson model, where the system's initial state is given by a single tensor product of $n$-fermionic states in real space, with $n<L$. Then, for all lattice sites, we have that $\N_{jj}$ is either zero or one. The $\N_{jk}$-matrix entries can then be evaluated as 

\begin{align*}
    \langle d_j^\dagger d_k \rangle = \sum_{i,j = 1}^{n < L} A_{ik} A_{jl} \langle f_i^\dagger f_j \rangle = \sum_{j=1} A_{jk} A_{jl} \langle f_j^\dagger f_j \rangle,
    \label{real system correlations}
\end{align*}

which can then be numerically computed to obtain the LHS expectation value. In general, this $\N_{jk}$-matrix will not be diagonal, which is reasonable since the system's real configuration is not an eigenstate. In principle and in practice, by inverting \eqref{real system correlations}, we can evolve any number operator or two-body correlation operator, ie.

\begin{align}
    \langle f_j^\dagger f_k \rangle = \sum_{k,l =1}^{n} A_{jk} A_{jl} \langle d_k^\dagger d_l \rangle.
\end{align}

This quantities' time evolution can then be found out to be 

\begin{equation}
    \langle f_j^\dagger(t) f_k(t) \rangle = \sum_{k,l =1}^{L} e^{i(\epsilon_k - \epsilon_l)t}A_{jk} A_{jl} \langle d_k^\dagger d_l \rangle,
\end{equation}

which can then be numerically solved. 

\clearpage 

%\section{Independent Electrons and Static Crystals}

%\subsection{Crystal lattices} 

%The mathematical concept which best describes an actual crystal lattice is that of a Bravais lattice, defined as a set of mathematical points corresponding to the discrete positions in space given by 

%\begin{equation}
 %   \{\Rb \in \R^{3} \blanky | \blanky \R = \sum_{i=1}^{3} n_i {\bf a}_i \textnormal{ with } n_i \in \mathds{Z}\},
%\end{equation}
    
%where the $\{a_i\}$-vector are the so-called primitive vector. The Bravais lattice is invariant under the operation 

%$$
%\Rb \rightarrow \Rb + {\bf T} \textnormal{ where } {\bf %T} = \sum_{i=1}^{3} L_i {\bf a}_i \blanky | \blanky L_i %\in \mathds{Z}
%

\clearpage

%\section{Independent Electrons and Static Crystals}

%\subsection{Crystal lattices} 

%The mathematical concept which best describes an actual crystal lattice is that of a Bravais lattice, defined as a set of mathematical points corresponding to the discrete positions in space given by 

%\begin{equation}
 %   \{\Rb \in \R^{3} \blanky | \blanky \R = \sum_{i=1}^{3} n_i {\bf a}_i \textnormal{ with } n_i \in \mathds{Z}\},
%\end{equation}
    
%where the $\{a_i\}$-vector are the so-called primitive vector. The Bravais lattice is invariant under the operation 

%$$
%\Rb \rightarrow \Rb + {\bf T} \textnormal{ where } {\bf %T} = \sum_{i=1}^{3} L_i {\bf a}_i \blanky | \blanky L_i %\in \mathds{Z}
%

\clearpage

\section{Photons: coupling to electrons}

Phonons are quantized vibrations and play a fundamental role in sound physics, specific heat, elasticity and electrical resistivity of solids. More surprisingly, the electron-phonon coupling is the cause of conventional superconductivity. There are two distinct models for electron-phonon coupling, the jellium model, where the ions are represented by a smeared-out continuous positive background, and the lattice model where the ions oscillate around their equilibrium positions forming a crystal lattice. \\

Phonons are basically harmonic oscillators, they are bosons. Moreover, these naturally occur at finite temperature, so the thermal distribution function for bosons will be used. \\

\paragraph{\textbf{Jellium oscillations and Einstein phonons}}

Let $\rho^0_{\textnormal{ion}}$ be the particle density of the ion jellium and let $\rho^0_{\textnormal{el}} = Z \rho^0_{\textnormal{ion}}$ that of the homogeneous electron gas. Consider slow ionic density oscillations in a static electron gas, where the restoring force is the long range Coulomb interaction, where the electron dynamics are neglected as well. This entails that $\rho_{\textnormal{ext}}$ is a fixed constant. In the limit of small harmonic deviations from the equilibrium, $\delta \rho_{\textnormal{ion}}(x^\mu) = \delta \rho_{\textnormal{ion}} ({\bf x}) e^{-i\Omega t}$. The equations of motion are linear up to first order in the ionic density variations, thus its solutions can be written as 

\begin{equation}
    \rho_{\textnormal{ion}}(x^\mu) = \rho^0_{\textnormal{ion}} + \delta \rho_{\textnormal{ion}} ({\bf x}) e^{-i\Omega t}.
\end{equation}

A non-zero $\delta \rho_{\textnormal{ion}}$ corresponds to a charge density $Z e \delta \rho_{\textnormal{ion}}$ and hence is associated with an electric field ${\bf E}$ which must obey Maxwell's equations, ie.

\begin{align}
    \nabla \cdot {\bf E} &= \frac{Ze}{\epsilon_0} \delta \rho_{\textnormal{ion}} & \Rightarrow  \nabla \cdot \bm{\mathfrak{f}} &= \frac{Z^2 e^2 \rho^0_{\textnormal{ion}} }{\epsilon_0} \delta \rho_{\textnormal{ion}},
\end{align}

where $\bm{\mathfrak{f}} = Z e \rho_{\textnormal{ion}} {\bf E} \approx Z e \rho^0_{\textnormal{ion}} {\bf E}$ is a force density written upto first order in $\delta \rho_{\textnormal{ion}}$. This force equation is supplemented by the continuity equation, $\partial_{\mu} J^\mu = 0$, where $J^\mu = (\rho_{\textnormal{ion}}, \rho_{\textnormal{ion}} {\bf v})$. This equation can be rewritten as 

$$
\partial_t \delta \rho_{\textnormal{ion}} +  \rho^0_{\textnormal{ion}} \nabla \cdot {\bf v} + \mathcal{O}(\delta^2 \rho_{\textnormal{ion}}) = 0,
$$

since the velocity is already a small quantity. Differentiating this with respect to time once and again and using Newton's second law $\bm{\mathfrak{t}} = M \rho_{\textnormal{ion}} \partial_t {\bf v}$ yields 


\clearpage
\section{Linear Response Theory}

Linear response theory is an extremely widely used concept in physics, stating that the response to a weak external perturbation is proportional to the perturbation, and therefore the quantity of interest is the proportionality constant. The physical question to ask is thus: supposing some perturbation $H'$, what is the measured consequence for an observable quantity ${\bf A}$. In other words, what is $\langle {\bf A} \rangle$ to linear order in $H'$? 

Among the numerous physical application of the linear response formalism, one can mention charge and spin susceptibilities of eg. electron systems due to external electric or magnetic fields. Responses to external mechanical forces or vibrations can also be calculated using the same formalism. \\

\paragraph{\textbf{The general Kubo formula}}

Consider a quantum system described by a time independent Hamiltonian ${\bf H}_0$ in thermodynamic equilibrium. This means that an expectation value of a physical quantity, described by the operator ${\bf A}$, which can be evaluated as 

\begin{equation}
    \begin{split}
        \langle {\bf A} \rangle = \frac{1}{\mathcal{Z}_0} \textnormal{Tr }_{\mathds{H}} \rho_0 {\bf A}  = \frac{1}{\mathcal{Z}_0} \sum_{n \in \Lambda} \bra{n} {{\bf A}} \ket{n} e^{-\beta E_n} \\
        \rho_0 = e^{-\beta {\bf H}_0} = \sum_{n \in \Lambda} \ket{n} \bra{n} e^{-\beta E_n},
    \end{split} \begin{array}{c}
         \textnormal{ where $\{\ket{n}\}_{n \in \Lambda}$ is a complete} \\
         \\
         \textnormal{set of eigenstates}.
    \end{array}
\end{equation}

Suppose now that at some time, $t = t_0$, an external perturbation is applied to the system, driving it out of equilibrium. The perturbation is described by an additional time dependent term in the Hamiltonian 

\begin{equation}
    \Hamiltonian(t) = \Hamiltonian_0 + \Hamiltonian'(t) \theta(t-t_0)
\end{equation}

Now, the interest lies in finding the expectation value of the ${\bf A}$ operator at times $t$ greater that $t_0$-. In order to do so, the time evolution of the density matrix must be found, or equivalently the time evolution of the eigenstates of the unperturbed Hamiltonian. Once $\ket{n(t)}$ is found, the time-dependent expectation value can be found as 

\begin{align}
        \langle {\bf A}(t) \rangle = \frac{1}{\mathcal{Z}_0} \textnormal{Tr }_{\mathds{H}} \rho(t) {\bf A}  = \frac{1}{\mathcal{Z}_0} \sum_{n \in \Lambda} \bra{n(t)} {{\bf A}} \ket{n(t)} e^{-\beta E_n} \\
        \rho_0 = e^{-\beta {\bf H}_0} = \sum_{n \in \Lambda} \ket{n(t)} \bra{n(t)} e^{-\beta E_n},
\end{align}

The physical idea behind this expression is as follows. The initial states of the system are distributed according to the usual Boltzmann distribution $\frac{e^{-\beta E_{0n}}}{\mathcal{Z_0}}$. At later times, the system is described by the same distribution of states but the states are now time-dependent and they have evolved according to the new Hamiltonian. The time dependence of the states $\ket{n(t)}$ is governed by the Schr\"odinger equation. Since $\Hamiltonian'$ is regarded to be a small perturbation, the interaction picture representation is suitable for this setting. In this representation, the time dependence is given by 

\begin{equation}
    \ket{n(t)} = e^{-i\Hamiltonian_0 t} \ket{n(t)}_I = e^{-i\Hamiltonian_0 t} \mathcal{U}(t, t_0) \ket{\hat{n}(t_0)},
\end{equation}

where by definition $\ket{\hat{n}(t_0)} = e^{i \Hamiltonian_0 t_0} \ket{n(t_0)} = \ket{n}$.

Up to linear order in $\Hamiltonian'$, the time evolution operator $\mathcal{U}(t, t_0)$ can be written 

$$
    \mathcal{U}(t, t_0) = \mathds{1} - i \int_{t_0}^t dt' \Hamiltonian'(t') + \mathcal{O}(\Hamiltonian^{'2})
$$

Then, using this in the time-dependent expectation value yields 

\begin{equation} \begin{split}
    \langle {\bf A}(t) \rangle &= \frac{1}{\mathcal{Z}_0} \sum_{n \in \Lambda} \bra{n(t)} {{\bf A}} \ket{n(t)} e^{-\beta E_n} \\
    &= \frac{1}{\mathcal{Z}_0} \sum_{n \in \Lambda} \bra{n(t_0)} \bigg(\mathds{1} - i \int_{t_0}^t dt' \Hamiltonian'(t')\bigg) e^{-i \Hamiltonian_0 t_0} {{\bf A}} e^{i \Hamiltonian_0 t_0} \bigg(\mathds{1} - i \int_{t_0}^t dt' \Hamiltonian'(t')\bigg) \ket{n(t_0)}  e^{-\beta E_n}+ \mathcal{O}(\Hamiltonian^{'2}) \\
    &= \frac{1}{\mathcal{Z}_0} \sum_{n \in \Lambda} \bra{n(t_0)} {{\bf A}} \ket{n(t_0)} - \frac{i}{\mathcal{Z}_0} \int_{t_0}^{t} dt' \sum_{n \in \Lambda} e^{-\beta E_n} \bigg( e^{-i \Hamiltonian_0 t_0} {{\bf A}} e^{i \Hamiltonian_0 t_0} \Hamiltonian'(t') - \Hamiltonian'(t')e^{-i \Hamiltonian_0 t_0} {{\bf A}} e^{i \Hamiltonian_0 t_0} \ket{n(t_0)} \bigg) \\
    &= \langle {{\bf A}} \rangle_{0} + \int_{t_0}^{t} \frac{dt'}{i} \langle[{{\bf A}}(t), \Hamiltonian'(t')]\rangle_{0},
\end{split}
\end{equation}

where the brackets $\langle \rangle_{0}$ means an equilibrium average with respect to the Hamiltonian $\Hamiltonian$. This is in fact a remarkable and very useful result since the inherently non-equilibrium quantity $\langle {{\bf A}}(t) \rangle$ has been expressed as a correlation function of the system in equilibrium. The physical reason for this is that the interaction between excitations created in the non-equilibrium state is an effect to second order in the weak perturbation, hence not included in the linear response. \\

The correlation function is the retarded correlation function, which can be rewritten as 
the difference between $\langle {{\bf A}}(t) \rangle \textnormal{ and } \langle {{\bf A}}\rangle_0 $ ie. 

\begin{align} 
        & \alignedbox{\delta \langle {{\bf A}}(t) \rangle }{
        = \int_{t_0}^{\infty} dt' \mathcal{C}_{AH'}^{R}(t,t') e^{-\eta(t-t')} \textnormal{ where } \mathcal{C}_{AH'}^{R}(t,t') = -i \theta(t-t') \langle[{{\bf A}}(t), \Hamiltonian'(t')]\rangle_{0}},
\end{align}

which is the Kubo formula. This expresses the linear response to a perturbation $\Hamiltonian'$. Note that the factor $e^{-\eta(t-t')}$, with an infinitesimal positive parameter $\eta$, has been included to force the response at time $t$ due to the influence of $\Hamiltonian'$ at time $t'$ to decay when $t >> t'$. At the end of the calculation, the limit $\eta \rightarrow 0^+$,. This is so since the retarded effect of a perturbation must decrease in time\footnote{The other, the advanced correlation function is non-physical and must be ditched. The other one, the retarded correlation function, decreases exponentially with time, the exponential factor thus picks out the physically relevant solution by introducing an artificial relaxation mechanism.}. \\

\paragraph{\textbf{Kubo fromula in the frequency domain}}

It is often convenient to express the response to an external disturbance in the frequency domain via Fourier transformations\footnote{Consider the $L^1$-space, ie. the space of all integrable functions on the real line. Then the Fourier transform and the Fourier-anti trasnform can be defined as 
\begin{align}
    \mathcal{F}[f(t)](\omega) = f(\omega) = \int_{\R} dt e^{i\omega t} f(t) \blanky \textnormal{ and } \blanky \mathcal{F}^{-1}[f(\omega)](t) = f(t) = \int_{\R} \frac{d\omega}{2\pi} e^{-i\omega t} f(\omega)
\end{align}

}. Therefore, consider the perturbation Hamiltonian $\Hamiltonian'$, which can be rewritten in terms of its Fourier components 

\begin{equation}
    \Hamiltonian'(t) = \int_{\Omega \subset \R} \frac{d\omega}{2\pi} e^{-i\omega t} \Hamiltonian'_\omega,
\end{equation}

such that the retarded correlation function becomes 

\begin{equation}
    \mathcal{C}_{AH'}^{R}(t,t') = \int_{\mathds{R}} \frac{d\omega}{2\pi} e^{-i\omega t'} \mathcal{C}_{AH'_\omega}^{R}(t-t') \begin{array}{c}
         \textnormal{since $\langle[{{\bf A}}(t), \Hamiltonian'(t')_{\omega'}]\rangle_{0}$ only depends } \\
         \textnormal{ on the difference between $t$ and $t'$. }
    \end{array}
\end{equation}

Therefore, inserting this result into the Kubo formula yields

\begin{equation}
    \begin{split}
        \delta \langle {{\bf A}}(t) \rangle
        &= \int_{t_0}^{\infty} dt' \mathcal{C}_{AH'_\omega}^{R}(t,t') e^{-\eta(t-t')} \\
        &= \int_{\R} dt' \int_{\R} \frac{d\omega}{2\pi} e^{-i\omega t} e^{-i(\omega + i\eta) (t'-t)} \mathcal{C}_{AH'_\omega}^{R}(t-t') \\
        &= \int_{\R} \frac{d\omega}{2\pi} e^{-¿i\omega t} \bigg(\int_{\R} d(t'-t) e^{-i(\omega + i\eta)(t'-t)} \mathcal{C}_{AH'_\omega}^{R}(t-t')\bigg) \\
        &= \int_{\R} \frac{d\omega}{2\pi} e^{-i\omega t} \mathcal{C}_{AH'_\omega}^{R}(\omega; \eta) 
    \end{split}
\end{equation}

which can be inverted to yield the final result in the frequency domain

\begin{equation}
    \begin{split}
        \int_{\R} {dt} e^{i\nu t}
        \delta \langle {{\bf A}}(t) \rangle &= \int_{\R} {dt} e^{i\nu t} \int_{\R} \frac{d\omega}{2\pi} e^{-i\omega t} \mathcal{C}_{AH'_\omega}^{R}(\omega; \eta) \\
        \langle {{\bf A}}_\nu \rangle &= \int_{\R} \frac{d\omega}{2\pi} \int_{\R} dt e^{i(\nu - \omega)t} \mathcal{C}_{AH'_\omega}^{R}(\omega; \eta) \\
        &= \int_{\R} {d\omega} \delta(\nu - \omega) \mathcal{C}_{AH'_\omega}^{R}(\omega; \eta) \\
        &= \mathcal{C}_{AH'_\nu}^{R}(\nu; \eta) 
    \end{split}
\end{equation}

\begin{align}
       & \alignedbox{\Rightarrow \delta \langle {{\bf A}}_\omega \rangle = \mathcal{C}_{AH'_\omega}^{R}(\omega) \textnormal{ with } \mathcal{C}_{AH'_\omega}^{R}(\omega)}{ = \int_{\R} dt e^{i\omega t} e^{-\eta t} \mathcal{C}_{AH'_\omega}^{R}(t)},
\end{align}

{where the infinitesimal $\eta$ parameter is incorporated } { in order to ensure the correct physical result, ie.} {the retarded response function decays at $t>>1$.} \\

\paragraph{\textbf{Kubo formula for conductivity}}

Consider a system of charged particles, eg. electrons, which is subjected t an external electromagnetic field. The electromagnetic field induces a current and the conductivity is the linear response coefficient. In the general case, the conductivity is a non-local quantity in both time and space, such that the electric current ${{\bf J}_e}$ at some point ${\bf x}$ at time $t$ depends on the electric field at points ${\bf y}$ at times $t'$, eg.\footnote{Note that this section's mathematical treatment is not Lorentz-covariant. This is, the spacetime is treated as $\R^4$ with the metric being $g_{\mu \nu} = \delta_{\mu \nu}$} 

\begin{equation}
    J^{\alpha}_{e}(x^\mu) = \int_{\Omega \subset \R^4 } dx^{\mu} \sum_{\alpha \beta} \sigma_{\beta}(x^\mu, y^{\mu}) E^{\beta} (y^{\mu}), \begin{array}{c} 
         \textnormal{ where $\sigma_{\alpha \beta}(x^\mu, y^{\mu})$ is the conductivity tensor, which  } \\ 
         \textnormal{ describes the current response in the } \\
         \textnormal{ ${\bf e}_\alpha$-direction to an applied }
         \textnormal{ electric field in the ${\bf e}_\beta$-direction.}
    \end{array}
\end{equation}

The electric field ${\bf E}$ is given by the electric potential $\phi_{ext}$ and the vector potential ${\bf A}_{\textnormal{ext}}$ as $
{\bf E}(x^\mu) = -\partial_{\mu} A^{\mu}$. For electrons, the current density can be written as ${\bf J}_e = -e \langle {\bf J} \rangle$. The perturbing term in the Hamiltonian due to the external electromagnetic field is given by the coupling of the electrons to both the scalar potential and the vector potential. Then, upto linear order in the external potential, 

$$
\Hamiltonian_{\textnormal{ext}} = -e \int_{\R^3} d{\bf x} J_{\mu}({\bf x}) A^{\mu}_{\textnormal{ext}}(x^{\mu}).
$$

Let, ${\bf A}_0$ denote the vector potential in the equilibrium ie. prior to the onset of the perturbation ${\bf A}_0(x^{\mu}$ and let ${\bf A}_0(x^{\mu})$ denote the total vector potential. Then, 

$$
   {\bf A}(x^{\mu}) = {\bf A}_{0}(x^{\mu}) +  {\bf A}_{\textnormal{ext}}(x^{\mu}).
$$

The current operator can be decomposed in two components, the diamagnetic and the paramagnetic terms, as follows 

\begin{equation}
    {\bf J} = {\bf J}^{\nabla}({\bf x}) + \frac{e}{m} {\bf A}({\bf x}) \rho({\bf x}).  
\end{equation}

For simplicity and using gauge invariance, the external electric potential can be set to zero. The conductivity is most easily expressed in the frequency domain via a Fourier transformation of the perturbation. Since 

\begin{equation} \begin{array}{cc}
     \partial_t \overset{\mathcal{F}}{\rightarrow} -i\omega \blanky & \textnormal{ then } \blanky {\bf A}_{\textnormal{ext}}({\bf x}, \omega) \overset{\mathcal{F}}{\rightarrow}  \frac{1}{i\omega} {\bf E}_{\textnormal{ext}}({\bf x}, \omega) \\
\end{array}
     \Rightarrow \Hamiltonian_{\textnormal{ext}, \omega} = \frac{e}{i\omega} \int_{\Omega \subset \R^3} d{\bf x} \blanky {\bf J}({\bf x}) \cdot {\bf E}_{\textnormal{ext}}({\bf x}, \omega).
\end{equation}

In order to exploit the frequency domain formulation of linear response theory, it is desirable to find the corresponding formula for the conductivity tensor in frequency-space. The conductivity tensor is a property of the equilibrium system and can thus onyly depend on time differences $ \sigma_{\alpha \beta}(x^\mu, y^{\mu}) =  \sigma_{\alpha \beta}({\bf x},{\bf y}, t-t')$. The frequency transform of the conductivity yields

\begin{equation}
    J^{\alpha}_{e}({\bf x}, \omega) = \int_{\Omega \subset \R^3 } d{\bf y} \blanky \sum_{ \beta} \sigma_{\alpha \beta}({\bf x},{\bf y}, \omega) E^{\beta}({\bf y}, \omega).
\end{equation}

Now, given that he external perturbation, written in frequency space, is already linear in the external potential ${\bf E}_{\textnormal{ext}}$, and given that the interest lies only on terms proportional to said perturbation, the conductivity can be rewritten as 

\clearpage

\section{.}
 
\end{document}
